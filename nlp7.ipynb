{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras 서브 클래싱 API\n",
    "앞으로 자주사용하게 될 것 같다 pytorch를 하다보면 class를 nn.Module을 통해서 상속 받고 함수를 만들었었다.\n",
    "이와 같이 서브클래스를 만들어서 조작하는 것을 나타낸다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 4380.4507 - mse: 4380.4507\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 540.1000 - mse: 540.1000\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 67.5726 - mse: 67.5726\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.4300 - mse: 9.4300\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.2745 - mse: 2.2745\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.3926 - mse: 1.3926\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2825 - mse: 1.2825\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2675 - mse: 1.2675\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2642 - mse: 1.2642\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2623 - mse: 1.2623\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2606 - mse: 1.2606\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2590 - mse: 1.2590\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2573 - mse: 1.2573\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2557 - mse: 1.2557\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2541 - mse: 1.2541\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2525 - mse: 1.2525\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2510 - mse: 1.2510\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2494 - mse: 1.2494\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2478 - mse: 1.2478\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2463 - mse: 1.2463\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2448 - mse: 1.2448\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2432 - mse: 1.2432\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2417 - mse: 1.2417\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2403 - mse: 1.2403\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.2388 - mse: 1.2388\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.2373 - mse: 1.2373\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2359 - mse: 1.2359\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2344 - mse: 1.2344\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2330 - mse: 1.2330\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2316 - mse: 1.2316\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2302 - mse: 1.2302\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2288 - mse: 1.2288\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2274 - mse: 1.2274\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2260 - mse: 1.2260\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2246 - mse: 1.2246\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2233 - mse: 1.2233\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2219 - mse: 1.2219\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2206 - mse: 1.2206\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2193 - mse: 1.2193\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2180 - mse: 1.2180\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2167 - mse: 1.2167\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2154 - mse: 1.2154\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2141 - mse: 1.2141\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2129 - mse: 1.2129\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2116 - mse: 1.2116\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2104 - mse: 1.2104\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2091 - mse: 1.2091\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2079 - mse: 1.2079\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2067 - mse: 1.2067\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2055 - mse: 1.2055\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2043 - mse: 1.2043\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2031 - mse: 1.2031\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2019 - mse: 1.2019\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2008 - mse: 1.2008\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1996 - mse: 1.1996\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1985 - mse: 1.1985\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.1973 - mse: 1.1973\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1962 - mse: 1.1962\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1951 - mse: 1.1951\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1940 - mse: 1.1940\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1929 - mse: 1.1929\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1918 - mse: 1.1918\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1907 - mse: 1.1907\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1896 - mse: 1.1896\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1886 - mse: 1.1886\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1875 - mse: 1.1875\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1865 - mse: 1.1865\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1854 - mse: 1.1854\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1844 - mse: 1.1844\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1834 - mse: 1.1834\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1824 - mse: 1.1824\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1814 - mse: 1.1814\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1804 - mse: 1.1804\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1794 - mse: 1.1794\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1784 - mse: 1.1784\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1774 - mse: 1.1774\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1765 - mse: 1.1765\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1755 - mse: 1.1755\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1746 - mse: 1.1746\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1736 - mse: 1.1736\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1727 - mse: 1.1727\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1718 - mse: 1.1718\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1709 - mse: 1.1709\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1700 - mse: 1.1700\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1690 - mse: 1.1690\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1681 - mse: 1.1681\n",
      "Epoch 87/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1673 - mse: 1.1673\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1664 - mse: 1.1664\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1655 - mse: 1.1655\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.1646 - mse: 1.1646\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1638 - mse: 1.1638\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.1629 - mse: 1.1629\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1621 - mse: 1.1621\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1612 - mse: 1.1612\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1604 - mse: 1.1604\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1596 - mse: 1.1596\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1588 - mse: 1.1588\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.1580 - mse: 1.1580\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1572 - mse: 1.1572\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1564 - mse: 1.1564\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1556 - mse: 1.1556\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1548 - mse: 1.1548\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1540 - mse: 1.1540\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1532 - mse: 1.1532\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1525 - mse: 1.1525\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1517 - mse: 1.1517\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1510 - mse: 1.1510\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1502 - mse: 1.1502\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1495 - mse: 1.1495\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1487 - mse: 1.1487\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1480 - mse: 1.1480\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1473 - mse: 1.1473\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1466 - mse: 1.1466\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1459 - mse: 1.1459\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1452 - mse: 1.1452\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1445 - mse: 1.1445\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1438 - mse: 1.1438\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1431 - mse: 1.1431\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1424 - mse: 1.1424\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1417 - mse: 1.1417\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1410 - mse: 1.1410\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1404 - mse: 1.1404\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1397 - mse: 1.1397\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1391 - mse: 1.1391\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1384 - mse: 1.1384\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1378 - mse: 1.1378\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1371 - mse: 1.1371\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1365 - mse: 1.1365\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1359 - mse: 1.1359\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1353 - mse: 1.1353\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.1346 - mse: 1.1346\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1340 - mse: 1.1340\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1334 - mse: 1.1334\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1328 - mse: 1.1328\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1322 - mse: 1.1322\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1316 - mse: 1.1316\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1310 - mse: 1.1310\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1304 - mse: 1.1304\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1299 - mse: 1.1299\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1293 - mse: 1.1293\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1287 - mse: 1.1287\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1282 - mse: 1.1282\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1276 - mse: 1.1276\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1270 - mse: 1.1270\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1265 - mse: 1.1265\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1259 - mse: 1.1259\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1254 - mse: 1.1254\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1249 - mse: 1.1249\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1243 - mse: 1.1243\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1238 - mse: 1.1238\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1233 - mse: 1.1233\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1228 - mse: 1.1228\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1223 - mse: 1.1223\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1217 - mse: 1.1217\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1212 - mse: 1.1212\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1207 - mse: 1.1207\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1202 - mse: 1.1202\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1197 - mse: 1.1197\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1192 - mse: 1.1192\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1188 - mse: 1.1188\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1183 - mse: 1.1183\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1178 - mse: 1.1178\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1173 - mse: 1.1173\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1168 - mse: 1.1168\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1164 - mse: 1.1164\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1159 - mse: 1.1159\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1155 - mse: 1.1155\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.1150 - mse: 1.1150\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.1146 - mse: 1.1146\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1141 - mse: 1.1141\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1137 - mse: 1.1137\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1132 - mse: 1.1132\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1128 - mse: 1.1128\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.1123 - mse: 1.1123\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1119 - mse: 1.1119\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1115 - mse: 1.1115\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1111 - mse: 1.1111\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1106 - mse: 1.1106\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1102 - mse: 1.1102\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1098 - mse: 1.1098\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1094 - mse: 1.1094\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1090 - mse: 1.1090\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1086 - mse: 1.1086\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1082 - mse: 1.1082\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1078 - mse: 1.1078\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1074 - mse: 1.1074\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1070 - mse: 1.1070\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1066 - mse: 1.1066\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1063 - mse: 1.1063\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1059 - mse: 1.1059\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1055 - mse: 1.1055\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1051 - mse: 1.1051\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1048 - mse: 1.1048\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1044 - mse: 1.1044\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1040 - mse: 1.1040\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1037 - mse: 1.1037\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1033 - mse: 1.1033\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1029 - mse: 1.1029\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1026 - mse: 1.1026\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1022 - mse: 1.1022\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1019 - mse: 1.1019\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1015 - mse: 1.1015\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1012 - mse: 1.1012\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1009 - mse: 1.1009\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1005 - mse: 1.1005\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1002 - mse: 1.1002\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0999 - mse: 1.0999\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0995 - mse: 1.0995\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0992 - mse: 1.0992\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0989 - mse: 1.0989\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0986 - mse: 1.0986\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0983 - mse: 1.0983\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0979 - mse: 1.0979\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0976 - mse: 1.0976\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0973 - mse: 1.0973\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0970 - mse: 1.0970\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0967 - mse: 1.0967\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0964 - mse: 1.0964\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0961 - mse: 1.0961\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0958 - mse: 1.0958\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0955 - mse: 1.0955\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0952 - mse: 1.0952\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0949 - mse: 1.0949\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0946 - mse: 1.0946\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0944 - mse: 1.0944\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0941 - mse: 1.0941\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0938 - mse: 1.0938\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0935 - mse: 1.0935\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0932 - mse: 1.0932\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0930 - mse: 1.0930\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0927 - mse: 1.0927\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0924 - mse: 1.0924\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0922 - mse: 1.0922\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0919 - mse: 1.0919\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0916 - mse: 1.0916\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0914 - mse: 1.0914\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0911 - mse: 1.0911\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0909 - mse: 1.0909\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0906 - mse: 1.0906\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0904 - mse: 1.0904\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0901 - mse: 1.0901\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0899 - mse: 1.0899\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0896 - mse: 1.0896\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0894 - mse: 1.0894\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0891 - mse: 1.0891\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0889 - mse: 1.0889\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0886 - mse: 1.0886\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0884 - mse: 1.0884\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0882 - mse: 1.0882\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0879 - mse: 1.0879\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0877 - mse: 1.0877\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0875 - mse: 1.0875\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0873 - mse: 1.0873\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0870 - mse: 1.0870\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0868 - mse: 1.0868\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0866 - mse: 1.0866\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0864 - mse: 1.0864\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0862 - mse: 1.0862\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0859 - mse: 1.0859\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0857 - mse: 1.0857\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0855 - mse: 1.0855\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0853 - mse: 1.0853\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0851 - mse: 1.0851\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0849 - mse: 1.0849\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0847 - mse: 1.0847\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0845 - mse: 1.0845\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0843 - mse: 1.0843\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0841 - mse: 1.0841\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0839 - mse: 1.0839\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0837 - mse: 1.0837\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0835 - mse: 1.0835\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0833 - mse: 1.0833\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0831 - mse: 1.0831\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0829 - mse: 1.0829\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0827 - mse: 1.0827\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0825 - mse: 1.0825\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0823 - mse: 1.0823\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0822 - mse: 1.0822\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0820 - mse: 1.0820\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0818 - mse: 1.0818\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0816 - mse: 1.0816\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0814 - mse: 1.0814\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0813 - mse: 1.0813\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0811 - mse: 1.0811\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0809 - mse: 1.0809\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0807 - mse: 1.0807\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0806 - mse: 1.0806\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0804 - mse: 1.0804\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0802 - mse: 1.0802\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0801 - mse: 1.0801\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0799 - mse: 1.0799\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0797 - mse: 1.0797\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0796 - mse: 1.0796\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0794 - mse: 1.0794\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0793 - mse: 1.0793\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0791 - mse: 1.0791\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0789 - mse: 1.0789\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0788 - mse: 1.0788\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0786 - mse: 1.0786\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0785 - mse: 1.0785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20e43fd88e0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "class Linear_model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Linear_model,self).__init__()\n",
    "        self.linear = tf.keras.layers.Dense(1,input_dim=1,activation='linear')\n",
    "    def call(self,x):\n",
    "        #x = self.input_layer(x)\n",
    "        y_pred = self.linear(x)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "model = Linear_model()\n",
    "X = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=np.float32)  # Convert to NumPy array\n",
    "y = np.array([11, 22, 33, 44, 53, 66, 77, 87, 95], dtype=np.float32)  # Convert to NumPy array\n",
    "X = X.reshape(-1, 1)\n",
    "\n",
    "sgd = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "model.compile(optimizer=sgd, loss='mse', metrics=['mse'])\n",
    "model.fit(X, y, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[54.283012]], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_x = np.array([5])\n",
    "text_x = text_x.reshape(-1,1)\n",
    "model.predict(text_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다층 퍼셉트론을 구성해서 텍스트를 분류해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'바나나': 1, '먹고': 2, '싶은': 3, '사과': 4, '길고': 5, '노란': 6, '저는': 7, '과일이': 8, '좋아요': 9}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "texts = ['먹고 싶은 사과', '먹고 싶은 바나나', '길고 노란 바나나 바나나', '저는 과일이 좋아요']\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 2. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]]\n",
      "binary [[0. 0. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]]\n",
      "freq [[0.         0.         0.33333333 0.33333333 0.33333333 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.33333333 0.33333333 0.33333333 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.5        0.         0.         0.         0.25\n",
      "  0.25       0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.33333333 0.33333333 0.33333333]]\n",
      "tfidf [[0.         0.         0.84729786 0.84729786 1.09861229 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.84729786 0.84729786 0.84729786 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         1.43459998 0.         0.         0.         1.09861229\n",
      "  1.09861229 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         1.09861229 1.09861229 1.09861229]]\n"
     ]
    }
   ],
   "source": [
    "#keras의 texts_to_matrix를 사용해보자\n",
    "print(tokenizer.texts_to_matrix(texts,mode='count'))\n",
    "print('binary',tokenizer.texts_to_matrix(texts,mode='binary'))\n",
    "print('freq',tokenizer.texts_to_matrix(texts,mode='freq'))\n",
    "print('tfidf',tokenizer.texts_to_matrix(texts,mode='tfidf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mode를 count를 사용하게 되면 count해서 행렬로 만들어준다. 다만 0부터 시작하기 때문에 index가 1부터 시작하는 tokenizer를 사용하면 맨 앞에 0으로 되어있는 것을 확인할 수 있다.\n",
    "binary는 나왔냐 안나왔냐만, freqency는 count 기반으로 나눠주고, tfidf는 TF-IDF 행렬을 만들어준다(빈도에 자연로그씌우고 1을 더한값)\n",
    "\n",
    "다음은 20개 뉴스 그룹 데이터에 대한 이해를 보여준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "#사이킷런엔 20개의 서로 다른 주제를 가지고 있는 18,846개의 뉴스그룹 이메일 데이터를 공개해놨다.\n",
    "news_data = fetch_20newsgroups(subset='train') # subset에 train 설정해주면 train set만 리턴해준다.\n",
    "print(news_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set 갯수 11314\n"
     ]
    }
   ],
   "source": [
    "print('training set 갯수',len(news_data.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 주제의 갯수 20\n"
     ]
    }
   ],
   "source": [
    "print('총 주제의 갯수',len(news_data.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 실습의 목표는 이메일 본문을 보고 20개의 주제 중 어떤 주제인지 맞추는 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(news_data.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               email  target\n",
      "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...       7\n",
      "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...       4\n",
      "2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...       4\n",
      "3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...       1\n",
      "4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...      14\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(news_data.data,columns=['email'])\n",
    "data['target'] = pd.Series(news_data.target)\n",
    "print(data[:5])\n",
    "# Dataframe 해주고 target을 추가해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().values.any() #데이터에 null값이 있는지 확인해주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='target'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['target'].value_counts().plot(kind='bar') #target의 분포 확인해주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = news_data.data\n",
    "train_y = news_data.target\n",
    "\n",
    "test_data = fetch_20newsgroups(subset='test',shuffle=True)\n",
    "test_x = test_data.data\n",
    "test_y = test_data.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "num_classes = 20\n",
    "\n",
    "#데이터 전처리 실행\n",
    "def preprocessing_data(train_data,test_data,mode):\n",
    "    tokenizer = Tokenizer(num_words=vocab_size)# vocab_size 개수만큼의 단어만 사용한다.\n",
    "    tokenizer.fit_on_texts(train_data)\n",
    "    X_train = tokenizer.texts_to_matrix(train_data,mode=mode)#샘플 수 * vocab_size 만큼의 matrix생성\n",
    "    X_test = tokenizer.texts_to_matrix(test_data,mode=mode)\n",
    "    return X_train,X_test,tokenizer.index_word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 본문의 크기 : (11314, 10000)\n",
      "훈련 샘플 레이블의 크기 : (11314, 20)\n",
      "테스트 샘플 본문의 크기 : (7532, 10000)\n",
      "테스트 샘플 레이블의 크기 : (7532, 20)\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,wordindex = preprocessing_data(train_x,test_x,'binary')\n",
    "y_train = to_categorical(train_y)\n",
    "y_test = to_categorical(test_y)\n",
    "\n",
    "print('훈련 샘플 본문의 크기 : {}'.format(X_train.shape))\n",
    "print('훈련 샘플 레이블의 크기 : {}'.format(y_train.shape))\n",
    "print('테스트 샘플 본문의 크기 : {}'.format(X_test.shape))\n",
    "print('테스트 샘플 레이블의 크기 : {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "80/80 [==============================] - 4s 40ms/step - loss: 2.2983 - accuracy: 0.3312 - val_loss: 0.9905 - val_accuracy: 0.8322\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.8942 - accuracy: 0.7533 - val_loss: 0.4827 - val_accuracy: 0.8816\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.4337 - accuracy: 0.8884 - val_loss: 0.3594 - val_accuracy: 0.8913\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 3s 37ms/step - loss: 0.2586 - accuracy: 0.9337 - val_loss: 0.3104 - val_accuracy: 0.9108\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.1758 - accuracy: 0.9529 - val_loss: 0.2975 - val_accuracy: 0.9143\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.1202 - accuracy: 0.9707 - val_loss: 0.2947 - val_accuracy: 0.9117\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 3s 40ms/step - loss: 0.0886 - accuracy: 0.9807 - val_loss: 0.2856 - val_accuracy: 0.9187\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 3s 40ms/step - loss: 0.0783 - accuracy: 0.9843 - val_loss: 0.2983 - val_accuracy: 0.9117\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.0565 - accuracy: 0.9883 - val_loss: 0.3014 - val_accuracy: 0.9152\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 3s 38ms/step - loss: 0.0548 - accuracy: 0.9868 - val_loss: 0.3189 - val_accuracy: 0.9205\n",
      "[0.7329195141792297, 0.8227562308311462]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "\n",
    "def fit_and_eval(X_train,y_train,X_test,y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256,input_shape=(vocab_size,),activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128,activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes,activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    model.fit(X_train,y_train,batch_size=128,epochs=10,verbose=1,validation_split=0.1)\n",
    "    score=model.evaluate(X_test,y_test,batch_size=128,verbose=0)\n",
    "    return score\n",
    "\n",
    "score = fit_and_eval(X_train,y_train,X_test,y_test)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
