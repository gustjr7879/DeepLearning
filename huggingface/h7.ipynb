{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 한국어 사용하는 LLM 사용해보기 on cpu (gpu memory 6기가밖에 안되가지공,,)\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/DialoGPT-small')\n",
    "model = AutoModelForCausalLM.from_pretrained('microsoft/DialoGPT-small').to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DialoGPT: I'm not sure if you're joking or not, but I'm pretty sure it's a joke.\n"
     ]
    }
   ],
   "source": [
    "new_user_input_ids = tokenizer.encode(\"한국말해봐\" + tokenizer.eos_token,return_tensors='pt')\n",
    "bot_input_ids = new_user_input_ids\n",
    "result_chat = model.generate(bot_input_ids,max_length = 300, pad_token_id = tokenizer.eos_token_id)\n",
    "\n",
    "print(\"DialoGPT: {}\".format(tokenizer.decode(result_chat[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "dataset = datasets.load_dataset('jiwoochris/easylaw_kr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['instruction', 'output', 'input'],\n",
      "        num_rows: 2195\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "#instruction : 질문\n",
    "#output : 답변 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.modules of GPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-11): 12 x GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HOME\\anaconda3\\lib\\site-packages\\peft\\tuners\\lora\\layer.py:1059: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig,get_peft_model\n",
    "\n",
    "lora_r = 8 #rank setting\n",
    "lora_alpha = 32 #제한\n",
    "#lora_dropout = 0.05 #dropout설정\n",
    "lora_target_modules = ['c_attn','c_proj']\n",
    "print(model.modules)\n",
    "config = LoraConfig(\n",
    "    r = lora_r,\n",
    "    lora_alpha= lora_alpha,\n",
    "    target_modules= lora_target_modules,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model,config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['instruction', 'output', 'input'],\n",
      "        num_rows: 2195\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "batch_size = 2\n",
    "\n",
    "learning_rate = 1e-05\n",
    "gradient_accumulation_steps = 2\n",
    "output_dir = './output'\n",
    "world_size = 1\n",
    "ddp = world_size != 1\n",
    "group_by_length = False\n",
    "val_set_size = 0\n",
    "import transformers\n",
    "train_args = transformers.TrainingArguments(\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    warmup_steps=100,\n",
    "    num_train_epochs=num_epochs,\n",
    "    learning_rate=learning_rate,\n",
    "    bf16=False,\n",
    "    logging_steps=2,\n",
    "    evaluation_strategy=\"steps\" if val_set_size > 0 else \"no\",\n",
    "    eval_steps=200 if val_set_size > 0 else None,\n",
    "    output_dir=output_dir,\n",
    "    load_best_model_at_end=True if val_set_size > 0 else False,\n",
    "    ddp_find_unused_parameters=False if ddp else None,\n",
    "    report_to=\"none\",\n",
    "    group_by_length=group_by_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '[PAD]'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(50258, 768)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"data_collator = transformers.DataCollatorForSeq2Seq(tokenizer, return_tensors=\"pt\", padding=True)\n",
    "class TokenizerWrapper:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def tokenize_function(self, examples):\n",
    "        return self.tokenizer(\n",
    "            examples['instruction'],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "        ) \n",
    "    def tokenize_function_labels(self, examples):\n",
    "        return self.tokenizer(\n",
    "            examples['output'],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "        ) \n",
    "special_tokens = tokenizer.special_tokens_map\n",
    "print(special_tokens)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "def add_end_token_to_question(input_dict):\n",
    "    input_dict['instruction'] += special_tokens['bos_token']\n",
    "    input_dict['output'] += special_tokens['bos_token']\n",
    "    return input_dict\n",
    "\n",
    "train_data = train_data.map(add_end_token_to_question)\n",
    "tokenizer_wrapper = TokenizerWrapper(tokenizer)\n",
    "\n",
    "tokenized_dataset = train_data.map(tokenizer_wrapper.tokenize_function, batched=True, num_proc=4, remove_columns=['input'])\n",
    "tokenized_label = train_data.map(tokenizer_wrapper.tokenize_function, batched=True, num_proc=4, remove_columns=['input'])\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\"\"\"\n",
    "\n",
    "special_tokens = tokenizer.special_tokens_map\n",
    "print(special_tokens)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "def add_end_token_to_question(input_dict):\n",
    "    input_dict['instruction'] += special_tokens['bos_token']\n",
    "    input_dict['output'] += special_tokens['bos_token']\n",
    "    return input_dict\n",
    "\n",
    "train_data = train_data.map(add_end_token_to_question)\n",
    "def add_end_token_to_question(input_dict):\n",
    "    input_dict['instruction'] += special_tokens['bos_token']\n",
    "    input_dict['output'] += special_tokens['bos_token']\n",
    "    return input_dict\n",
    "\n",
    "train_data = train_data.map(add_end_token_to_question)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c129f2aa2a747f9aea7cf0a26b0cb99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2195 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5ad2dacff4f44508e4784045e90adaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2195 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 2181\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 14\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "import copy\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from typing import Dict, List\n",
    "\n",
    "MAX_LENGTH = 256\n",
    "\n",
    "# Function to generate token embeddings from text part of batch\n",
    "def _preprocess_batch(batch: Dict[str, List]):  \n",
    "    model_inputs = tokenizer(batch[\"instruction\"], max_length=MAX_LENGTH, truncation=True, padding='max_length')    \n",
    "    model_inputs[\"labels\"] = copy.deepcopy(model_inputs['input_ids'])\n",
    "    return model_inputs\n",
    "\n",
    "_preprocessing_function = partial(_preprocess_batch)\n",
    "\n",
    "# apply the preprocessing function to each batch in the dataset\n",
    "encoded_small_dataset = train_data['train'].map(\n",
    "        _preprocessing_function,\n",
    "        batched=True,\n",
    "        remove_columns=[\"instruction\", \"output\"],\n",
    ")\n",
    "processed_dataset = encoded_small_dataset.filter(lambda rec: len(rec[\"input_ids\"]) <= MAX_LENGTH)\n",
    "\n",
    "# splitting dataset\n",
    "split_dataset = processed_dataset.train_test_split(test_size=14, seed=0)\n",
    "print(split_dataset)\n",
    "\n",
    "# takes a list of samples from a Dataset and collate them into a batch, as a dictionary of PyTorch tensors.\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "        model = model, tokenizer=tokenizer, max_length=MAX_LENGTH, pad_to_multiple_of=8, padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HOME\\anaconda3\\lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = transformers.Trainer(\n",
    "    model = model,\n",
    "    train_dataset=split_dataset['train'],\n",
    "    args = train_args,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2333af621e014a9898847dbc21265bd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2725 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 148.9142, 'learning_rate': 2.0000000000000002e-07, 'epoch': 0.0}\n",
      "{'loss': 120.6206, 'learning_rate': 4.0000000000000003e-07, 'epoch': 0.01}\n",
      "{'loss': 209.8717, 'learning_rate': 6.000000000000001e-07, 'epoch': 0.01}\n",
      "{'loss': 164.6684, 'learning_rate': 8.000000000000001e-07, 'epoch': 0.01}\n",
      "{'loss': 165.9668, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.02}\n",
      "{'loss': 216.1205, 'learning_rate': 1.2000000000000002e-06, 'epoch': 0.02}\n",
      "{'loss': 181.2519, 'learning_rate': 1.4000000000000001e-06, 'epoch': 0.03}\n",
      "{'loss': 225.7728, 'learning_rate': 1.6000000000000001e-06, 'epoch': 0.03}\n",
      "{'loss': 163.6481, 'learning_rate': 1.8000000000000001e-06, 'epoch': 0.03}\n",
      "{'loss': 143.5117, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.04}\n",
      "{'loss': 172.7267, 'learning_rate': 2.2e-06, 'epoch': 0.04}\n",
      "{'loss': 203.627, 'learning_rate': 2.4000000000000003e-06, 'epoch': 0.04}\n",
      "{'loss': 212.5016, 'learning_rate': 2.6e-06, 'epoch': 0.05}\n",
      "{'loss': 136.0235, 'learning_rate': 2.8000000000000003e-06, 'epoch': 0.05}\n",
      "{'loss': 151.7913, 'learning_rate': 3e-06, 'epoch': 0.05}\n",
      "{'loss': 161.458, 'learning_rate': 3.2000000000000003e-06, 'epoch': 0.06}\n",
      "{'loss': 223.5731, 'learning_rate': 3.4000000000000005e-06, 'epoch': 0.06}\n",
      "{'loss': 158.2294, 'learning_rate': 3.6000000000000003e-06, 'epoch': 0.07}\n",
      "{'loss': 257.053, 'learning_rate': 3.8000000000000005e-06, 'epoch': 0.07}\n",
      "{'loss': 194.4232, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.07}\n",
      "{'loss': 187.1102, 'learning_rate': 4.2000000000000004e-06, 'epoch': 0.08}\n",
      "{'loss': 147.7694, 'learning_rate': 4.4e-06, 'epoch': 0.08}\n",
      "{'loss': 224.2787, 'learning_rate': 4.600000000000001e-06, 'epoch': 0.08}\n",
      "{'loss': 176.7687, 'learning_rate': 4.800000000000001e-06, 'epoch': 0.09}\n",
      "{'loss': 173.3375, 'learning_rate': 5e-06, 'epoch': 0.09}\n",
      "{'loss': 220.0415, 'learning_rate': 5.2e-06, 'epoch': 0.1}\n",
      "{'loss': 240.2021, 'learning_rate': 5.400000000000001e-06, 'epoch': 0.1}\n",
      "{'loss': 235.013, 'learning_rate': 5.600000000000001e-06, 'epoch': 0.1}\n",
      "{'loss': 207.4598, 'learning_rate': 5.8e-06, 'epoch': 0.11}\n",
      "{'loss': 179.8694, 'learning_rate': 6e-06, 'epoch': 0.11}\n",
      "{'loss': 156.0448, 'learning_rate': 6.200000000000001e-06, 'epoch': 0.11}\n",
      "{'loss': 243.9475, 'learning_rate': 6.4000000000000006e-06, 'epoch': 0.12}\n",
      "{'loss': 245.2067, 'learning_rate': 6.600000000000001e-06, 'epoch': 0.12}\n",
      "{'loss': 232.6479, 'learning_rate': 6.800000000000001e-06, 'epoch': 0.12}\n",
      "{'loss': 185.7174, 'learning_rate': 7e-06, 'epoch': 0.13}\n",
      "{'loss': 209.4542, 'learning_rate': 7.2000000000000005e-06, 'epoch': 0.13}\n",
      "{'loss': 207.2036, 'learning_rate': 7.4e-06, 'epoch': 0.14}\n",
      "{'loss': 206.0694, 'learning_rate': 7.600000000000001e-06, 'epoch': 0.14}\n",
      "{'loss': 184.6131, 'learning_rate': 7.800000000000002e-06, 'epoch': 0.14}\n",
      "{'loss': 175.4277, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.15}\n",
      "{'loss': 216.5418, 'learning_rate': 8.2e-06, 'epoch': 0.15}\n",
      "{'loss': 211.0504, 'learning_rate': 8.400000000000001e-06, 'epoch': 0.15}\n",
      "{'loss': 212.9928, 'learning_rate': 8.6e-06, 'epoch': 0.16}\n",
      "{'loss': 164.669, 'learning_rate': 8.8e-06, 'epoch': 0.16}\n",
      "{'loss': 226.9983, 'learning_rate': 9e-06, 'epoch': 0.16}\n",
      "{'loss': 161.5658, 'learning_rate': 9.200000000000002e-06, 'epoch': 0.17}\n",
      "{'loss': 199.2455, 'learning_rate': 9.4e-06, 'epoch': 0.17}\n",
      "{'loss': 215.6751, 'learning_rate': 9.600000000000001e-06, 'epoch': 0.18}\n",
      "{'loss': 185.7898, 'learning_rate': 9.800000000000001e-06, 'epoch': 0.18}\n",
      "{'loss': 180.8075, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 146.1551, 'learning_rate': 9.992380952380954e-06, 'epoch': 0.19}\n",
      "{'loss': 210.8115, 'learning_rate': 9.984761904761907e-06, 'epoch': 0.19}\n",
      "{'loss': 196.4915, 'learning_rate': 9.977142857142858e-06, 'epoch': 0.19}\n",
      "{'loss': 133.3884, 'learning_rate': 9.96952380952381e-06, 'epoch': 0.2}\n",
      "{'loss': 232.1507, 'learning_rate': 9.961904761904763e-06, 'epoch': 0.2}\n",
      "{'loss': 165.7323, 'learning_rate': 9.954285714285715e-06, 'epoch': 0.21}\n",
      "{'loss': 147.9615, 'learning_rate': 9.946666666666667e-06, 'epoch': 0.21}\n",
      "{'loss': 147.7778, 'learning_rate': 9.93904761904762e-06, 'epoch': 0.21}\n",
      "{'loss': 212.9013, 'learning_rate': 9.931428571428571e-06, 'epoch': 0.22}\n",
      "{'loss': 129.5142, 'learning_rate': 9.923809523809524e-06, 'epoch': 0.22}\n",
      "{'loss': 161.1457, 'learning_rate': 9.916190476190477e-06, 'epoch': 0.22}\n",
      "{'loss': 163.6722, 'learning_rate': 9.90857142857143e-06, 'epoch': 0.23}\n",
      "{'loss': 200.3088, 'learning_rate': 9.900952380952383e-06, 'epoch': 0.23}\n",
      "{'loss': 163.1929, 'learning_rate': 9.893333333333334e-06, 'epoch': 0.23}\n",
      "{'loss': 166.5961, 'learning_rate': 9.885714285714287e-06, 'epoch': 0.24}\n",
      "{'loss': 137.1277, 'learning_rate': 9.878095238095238e-06, 'epoch': 0.24}\n",
      "{'loss': 141.7779, 'learning_rate': 9.870476190476191e-06, 'epoch': 0.25}\n",
      "{'loss': 199.6861, 'learning_rate': 9.862857142857144e-06, 'epoch': 0.25}\n",
      "{'loss': 165.3087, 'learning_rate': 9.855238095238095e-06, 'epoch': 0.25}\n",
      "{'loss': 158.661, 'learning_rate': 9.847619047619048e-06, 'epoch': 0.26}\n",
      "{'loss': 154.8086, 'learning_rate': 9.84e-06, 'epoch': 0.26}\n",
      "{'loss': 160.964, 'learning_rate': 9.832380952380954e-06, 'epoch': 0.26}\n",
      "{'loss': 118.9765, 'learning_rate': 9.824761904761906e-06, 'epoch': 0.27}\n",
      "{'loss': 147.229, 'learning_rate': 9.81714285714286e-06, 'epoch': 0.27}\n",
      "{'loss': 189.7887, 'learning_rate': 9.80952380952381e-06, 'epoch': 0.27}\n",
      "{'loss': 183.7643, 'learning_rate': 9.801904761904763e-06, 'epoch': 0.28}\n",
      "{'loss': 171.8199, 'learning_rate': 9.794285714285714e-06, 'epoch': 0.28}\n",
      "{'loss': 134.4311, 'learning_rate': 9.786666666666667e-06, 'epoch': 0.29}\n",
      "{'loss': 127.8839, 'learning_rate': 9.77904761904762e-06, 'epoch': 0.29}\n",
      "{'loss': 156.6997, 'learning_rate': 9.771428571428571e-06, 'epoch': 0.29}\n",
      "{'loss': 116.6624, 'learning_rate': 9.763809523809524e-06, 'epoch': 0.3}\n",
      "{'loss': 146.9521, 'learning_rate': 9.756190476190477e-06, 'epoch': 0.3}\n",
      "{'loss': 141.3122, 'learning_rate': 9.74857142857143e-06, 'epoch': 0.3}\n",
      "{'loss': 134.6013, 'learning_rate': 9.740952380952383e-06, 'epoch': 0.31}\n",
      "{'loss': 153.5612, 'learning_rate': 9.733333333333334e-06, 'epoch': 0.31}\n",
      "{'loss': 138.8357, 'learning_rate': 9.725714285714287e-06, 'epoch': 0.32}\n",
      "{'loss': 120.2824, 'learning_rate': 9.718095238095238e-06, 'epoch': 0.32}\n",
      "{'loss': 131.2457, 'learning_rate': 9.71047619047619e-06, 'epoch': 0.32}\n",
      "{'loss': 111.8748, 'learning_rate': 9.702857142857144e-06, 'epoch': 0.33}\n",
      "{'loss': 126.542, 'learning_rate': 9.695238095238096e-06, 'epoch': 0.33}\n",
      "{'loss': 160.8591, 'learning_rate': 9.687619047619048e-06, 'epoch': 0.33}\n",
      "{'loss': 136.2282, 'learning_rate': 9.68e-06, 'epoch': 0.34}\n",
      "{'loss': 149.8772, 'learning_rate': 9.672380952380953e-06, 'epoch': 0.34}\n",
      "{'loss': 117.3989, 'learning_rate': 9.664761904761906e-06, 'epoch': 0.34}\n",
      "{'loss': 126.0284, 'learning_rate': 9.657142857142859e-06, 'epoch': 0.35}\n",
      "{'loss': 111.6863, 'learning_rate': 9.64952380952381e-06, 'epoch': 0.35}\n",
      "{'loss': 121.9816, 'learning_rate': 9.641904761904763e-06, 'epoch': 0.36}\n",
      "{'loss': 97.3104, 'learning_rate': 9.634285714285714e-06, 'epoch': 0.36}\n",
      "{'loss': 100.1982, 'learning_rate': 9.626666666666667e-06, 'epoch': 0.36}\n",
      "{'loss': 99.9628, 'learning_rate': 9.61904761904762e-06, 'epoch': 0.37}\n",
      "{'loss': 100.1757, 'learning_rate': 9.611428571428573e-06, 'epoch': 0.37}\n",
      "{'loss': 90.7328, 'learning_rate': 9.603809523809524e-06, 'epoch': 0.37}\n",
      "{'loss': 113.0102, 'learning_rate': 9.596190476190477e-06, 'epoch': 0.38}\n",
      "{'loss': 109.9464, 'learning_rate': 9.58857142857143e-06, 'epoch': 0.38}\n",
      "{'loss': 80.2326, 'learning_rate': 9.580952380952383e-06, 'epoch': 0.38}\n",
      "{'loss': 81.8168, 'learning_rate': 9.573333333333334e-06, 'epoch': 0.39}\n",
      "{'loss': 63.5758, 'learning_rate': 9.565714285714287e-06, 'epoch': 0.39}\n",
      "{'loss': 77.5167, 'learning_rate': 9.558095238095238e-06, 'epoch': 0.4}\n",
      "{'loss': 85.7579, 'learning_rate': 9.55047619047619e-06, 'epoch': 0.4}\n",
      "{'loss': 53.019, 'learning_rate': 9.542857142857143e-06, 'epoch': 0.4}\n",
      "{'loss': 56.2653, 'learning_rate': 9.535238095238096e-06, 'epoch': 0.41}\n",
      "{'loss': 33.7095, 'learning_rate': 9.52761904761905e-06, 'epoch': 0.41}\n",
      "{'loss': 56.3482, 'learning_rate': 9.52e-06, 'epoch': 0.41}\n",
      "{'loss': 47.5513, 'learning_rate': 9.512380952380953e-06, 'epoch': 0.42}\n",
      "{'loss': 61.0628, 'learning_rate': 9.504761904761906e-06, 'epoch': 0.42}\n",
      "{'loss': 29.5712, 'learning_rate': 9.497142857142859e-06, 'epoch': 0.43}\n",
      "{'loss': 55.6766, 'learning_rate': 9.48952380952381e-06, 'epoch': 0.43}\n",
      "{'loss': 49.1859, 'learning_rate': 9.481904761904763e-06, 'epoch': 0.43}\n",
      "{'loss': 36.7789, 'learning_rate': 9.474285714285714e-06, 'epoch': 0.44}\n",
      "{'loss': 34.5171, 'learning_rate': 9.466666666666667e-06, 'epoch': 0.44}\n",
      "{'loss': 32.4513, 'learning_rate': 9.45904761904762e-06, 'epoch': 0.44}\n",
      "{'loss': 34.2815, 'learning_rate': 9.451428571428573e-06, 'epoch': 0.45}\n",
      "{'loss': 33.8435, 'learning_rate': 9.443809523809526e-06, 'epoch': 0.45}\n",
      "{'loss': 38.2356, 'learning_rate': 9.436190476190477e-06, 'epoch': 0.45}\n",
      "{'loss': 29.4323, 'learning_rate': 9.42857142857143e-06, 'epoch': 0.46}\n",
      "{'loss': 31.4784, 'learning_rate': 9.420952380952382e-06, 'epoch': 0.46}\n",
      "{'loss': 25.7331, 'learning_rate': 9.413333333333334e-06, 'epoch': 0.47}\n",
      "{'loss': 27.4113, 'learning_rate': 9.405714285714286e-06, 'epoch': 0.47}\n",
      "{'loss': 27.7393, 'learning_rate': 9.398095238095238e-06, 'epoch': 0.47}\n",
      "{'loss': 37.3304, 'learning_rate': 9.39047619047619e-06, 'epoch': 0.48}\n",
      "{'loss': 24.1432, 'learning_rate': 9.382857142857143e-06, 'epoch': 0.48}\n",
      "{'loss': 23.5876, 'learning_rate': 9.375238095238096e-06, 'epoch': 0.48}\n",
      "{'loss': 29.9035, 'learning_rate': 9.367619047619049e-06, 'epoch': 0.49}\n",
      "{'loss': 32.0867, 'learning_rate': 9.360000000000002e-06, 'epoch': 0.49}\n",
      "{'loss': 25.0019, 'learning_rate': 9.352380952380953e-06, 'epoch': 0.49}\n",
      "{'loss': 24.1012, 'learning_rate': 9.344761904761906e-06, 'epoch': 0.5}\n",
      "{'loss': 28.0821, 'learning_rate': 9.337142857142859e-06, 'epoch': 0.5}\n",
      "{'loss': 31.7143, 'learning_rate': 9.32952380952381e-06, 'epoch': 0.51}\n",
      "{'loss': 20.1391, 'learning_rate': 9.321904761904763e-06, 'epoch': 0.51}\n",
      "{'loss': 24.8992, 'learning_rate': 9.314285714285714e-06, 'epoch': 0.51}\n",
      "{'loss': 25.4972, 'learning_rate': 9.306666666666667e-06, 'epoch': 0.52}\n",
      "{'loss': 26.4925, 'learning_rate': 9.29904761904762e-06, 'epoch': 0.52}\n",
      "{'loss': 24.4363, 'learning_rate': 9.291428571428572e-06, 'epoch': 0.52}\n",
      "{'loss': 20.8321, 'learning_rate': 9.283809523809525e-06, 'epoch': 0.53}\n",
      "{'loss': 24.9594, 'learning_rate': 9.276190476190477e-06, 'epoch': 0.53}\n",
      "{'loss': 23.9767, 'learning_rate': 9.26857142857143e-06, 'epoch': 0.54}\n",
      "{'loss': 26.558, 'learning_rate': 9.260952380952382e-06, 'epoch': 0.54}\n",
      "{'loss': 17.978, 'learning_rate': 9.253333333333333e-06, 'epoch': 0.54}\n",
      "{'loss': 18.7825, 'learning_rate': 9.245714285714286e-06, 'epoch': 0.55}\n",
      "{'loss': 16.9124, 'learning_rate': 9.238095238095239e-06, 'epoch': 0.55}\n",
      "{'loss': 19.3139, 'learning_rate': 9.23047619047619e-06, 'epoch': 0.55}\n",
      "{'loss': 20.5013, 'learning_rate': 9.222857142857143e-06, 'epoch': 0.56}\n",
      "{'loss': 20.1389, 'learning_rate': 9.215238095238096e-06, 'epoch': 0.56}\n",
      "{'loss': 18.1351, 'learning_rate': 9.207619047619049e-06, 'epoch': 0.56}\n",
      "{'loss': 18.5937, 'learning_rate': 9.200000000000002e-06, 'epoch': 0.57}\n",
      "{'loss': 21.0954, 'learning_rate': 9.192380952380953e-06, 'epoch': 0.57}\n",
      "{'loss': 22.6967, 'learning_rate': 9.184761904761906e-06, 'epoch': 0.58}\n",
      "{'loss': 21.7694, 'learning_rate': 9.177142857142859e-06, 'epoch': 0.58}\n",
      "{'loss': 20.856, 'learning_rate': 9.16952380952381e-06, 'epoch': 0.58}\n",
      "{'loss': 15.9688, 'learning_rate': 9.161904761904763e-06, 'epoch': 0.59}\n",
      "{'loss': 19.4708, 'learning_rate': 9.154285714285715e-06, 'epoch': 0.59}\n",
      "{'loss': 18.9214, 'learning_rate': 9.146666666666667e-06, 'epoch': 0.59}\n",
      "{'loss': 18.8911, 'learning_rate': 9.13904761904762e-06, 'epoch': 0.6}\n",
      "{'loss': 16.8479, 'learning_rate': 9.131428571428572e-06, 'epoch': 0.6}\n",
      "{'loss': 15.4615, 'learning_rate': 9.123809523809525e-06, 'epoch': 0.6}\n",
      "{'loss': 19.8751, 'learning_rate': 9.116190476190478e-06, 'epoch': 0.61}\n",
      "{'loss': 24.7393, 'learning_rate': 9.10857142857143e-06, 'epoch': 0.61}\n",
      "{'loss': 21.8335, 'learning_rate': 9.100952380952382e-06, 'epoch': 0.62}\n",
      "{'loss': 19.6937, 'learning_rate': 9.093333333333333e-06, 'epoch': 0.62}\n",
      "{'loss': 14.9195, 'learning_rate': 9.085714285714286e-06, 'epoch': 0.62}\n",
      "{'loss': 16.4701, 'learning_rate': 9.078095238095239e-06, 'epoch': 0.63}\n",
      "{'loss': 16.2119, 'learning_rate': 9.070476190476192e-06, 'epoch': 0.63}\n",
      "{'loss': 16.1251, 'learning_rate': 9.062857142857143e-06, 'epoch': 0.63}\n",
      "{'loss': 17.664, 'learning_rate': 9.055238095238096e-06, 'epoch': 0.64}\n",
      "{'loss': 16.3093, 'learning_rate': 9.047619047619049e-06, 'epoch': 0.64}\n",
      "{'loss': 18.6139, 'learning_rate': 9.040000000000002e-06, 'epoch': 0.65}\n",
      "{'loss': 15.3694, 'learning_rate': 9.032380952380954e-06, 'epoch': 0.65}\n",
      "{'loss': 16.1484, 'learning_rate': 9.024761904761906e-06, 'epoch': 0.65}\n",
      "{'loss': 19.6442, 'learning_rate': 9.017142857142858e-06, 'epoch': 0.66}\n",
      "{'loss': 13.7724, 'learning_rate': 9.00952380952381e-06, 'epoch': 0.66}\n",
      "{'loss': 12.4584, 'learning_rate': 9.001904761904762e-06, 'epoch': 0.66}\n",
      "{'loss': 16.7852, 'learning_rate': 8.994285714285715e-06, 'epoch': 0.67}\n",
      "{'loss': 13.5219, 'learning_rate': 8.986666666666666e-06, 'epoch': 0.67}\n",
      "{'loss': 13.3967, 'learning_rate': 8.97904761904762e-06, 'epoch': 0.67}\n",
      "{'loss': 19.7614, 'learning_rate': 8.971428571428572e-06, 'epoch': 0.68}\n",
      "{'loss': 21.6771, 'learning_rate': 8.963809523809525e-06, 'epoch': 0.68}\n",
      "{'loss': 13.6213, 'learning_rate': 8.956190476190478e-06, 'epoch': 0.69}\n",
      "{'loss': 13.9001, 'learning_rate': 8.948571428571429e-06, 'epoch': 0.69}\n",
      "{'loss': 14.53, 'learning_rate': 8.940952380952382e-06, 'epoch': 0.69}\n",
      "{'loss': 16.0363, 'learning_rate': 8.933333333333333e-06, 'epoch': 0.7}\n",
      "{'loss': 16.4988, 'learning_rate': 8.925714285714286e-06, 'epoch': 0.7}\n",
      "{'loss': 20.2651, 'learning_rate': 8.918095238095239e-06, 'epoch': 0.7}\n",
      "{'loss': 13.6836, 'learning_rate': 8.910476190476192e-06, 'epoch': 0.71}\n",
      "{'loss': 12.6637, 'learning_rate': 8.902857142857143e-06, 'epoch': 0.71}\n",
      "{'loss': 12.4199, 'learning_rate': 8.895238095238096e-06, 'epoch': 0.71}\n",
      "{'loss': 11.1015, 'learning_rate': 8.887619047619049e-06, 'epoch': 0.72}\n",
      "{'loss': 10.4654, 'learning_rate': 8.880000000000001e-06, 'epoch': 0.72}\n",
      "{'loss': 13.9426, 'learning_rate': 8.872380952380954e-06, 'epoch': 0.73}\n",
      "{'loss': 11.7343, 'learning_rate': 8.864761904761905e-06, 'epoch': 0.73}\n",
      "{'loss': 13.9565, 'learning_rate': 8.857142857142858e-06, 'epoch': 0.73}\n",
      "{'loss': 12.693, 'learning_rate': 8.84952380952381e-06, 'epoch': 0.74}\n",
      "{'loss': 11.2155, 'learning_rate': 8.841904761904762e-06, 'epoch': 0.74}\n",
      "{'loss': 12.3626, 'learning_rate': 8.834285714285715e-06, 'epoch': 0.74}\n",
      "{'loss': 12.5255, 'learning_rate': 8.826666666666668e-06, 'epoch': 0.75}\n",
      "{'loss': 18.7518, 'learning_rate': 8.819047619047619e-06, 'epoch': 0.75}\n",
      "{'loss': 9.4606, 'learning_rate': 8.811428571428572e-06, 'epoch': 0.76}\n",
      "{'loss': 11.4284, 'learning_rate': 8.803809523809525e-06, 'epoch': 0.76}\n",
      "{'loss': 13.2509, 'learning_rate': 8.796190476190478e-06, 'epoch': 0.76}\n",
      "{'loss': 11.833, 'learning_rate': 8.788571428571429e-06, 'epoch': 0.77}\n",
      "{'loss': 13.8311, 'learning_rate': 8.780952380952382e-06, 'epoch': 0.77}\n",
      "{'loss': 10.5928, 'learning_rate': 8.773333333333333e-06, 'epoch': 0.77}\n",
      "{'loss': 13.5136, 'learning_rate': 8.765714285714286e-06, 'epoch': 0.78}\n",
      "{'loss': 11.7377, 'learning_rate': 8.758095238095239e-06, 'epoch': 0.78}\n",
      "{'loss': 12.7419, 'learning_rate': 8.750476190476191e-06, 'epoch': 0.78}\n",
      "{'loss': 12.123, 'learning_rate': 8.742857142857144e-06, 'epoch': 0.79}\n",
      "{'loss': 11.3508, 'learning_rate': 8.735238095238096e-06, 'epoch': 0.79}\n",
      "{'loss': 8.9265, 'learning_rate': 8.727619047619048e-06, 'epoch': 0.8}\n",
      "{'loss': 9.0757, 'learning_rate': 8.720000000000001e-06, 'epoch': 0.8}\n",
      "{'loss': 11.936, 'learning_rate': 8.712380952380954e-06, 'epoch': 0.8}\n",
      "{'loss': 12.9465, 'learning_rate': 8.704761904761905e-06, 'epoch': 0.81}\n",
      "{'loss': 10.1712, 'learning_rate': 8.697142857142858e-06, 'epoch': 0.81}\n",
      "{'loss': 7.6897, 'learning_rate': 8.68952380952381e-06, 'epoch': 0.81}\n",
      "{'loss': 10.4684, 'learning_rate': 8.681904761904762e-06, 'epoch': 0.82}\n",
      "{'loss': 8.6056, 'learning_rate': 8.674285714285715e-06, 'epoch': 0.82}\n",
      "{'loss': 10.6685, 'learning_rate': 8.666666666666668e-06, 'epoch': 0.82}\n",
      "{'loss': 10.4931, 'learning_rate': 8.65904761904762e-06, 'epoch': 0.83}\n",
      "{'loss': 7.481, 'learning_rate': 8.651428571428572e-06, 'epoch': 0.83}\n",
      "{'loss': 8.8346, 'learning_rate': 8.643809523809525e-06, 'epoch': 0.84}\n",
      "{'loss': 8.3224, 'learning_rate': 8.636190476190478e-06, 'epoch': 0.84}\n",
      "{'loss': 11.6724, 'learning_rate': 8.628571428571429e-06, 'epoch': 0.84}\n",
      "{'loss': 8.7397, 'learning_rate': 8.620952380952382e-06, 'epoch': 0.85}\n",
      "{'loss': 9.4597, 'learning_rate': 8.613333333333333e-06, 'epoch': 0.85}\n",
      "{'loss': 8.1906, 'learning_rate': 8.605714285714286e-06, 'epoch': 0.85}\n",
      "{'loss': 8.4807, 'learning_rate': 8.598095238095238e-06, 'epoch': 0.86}\n",
      "{'loss': 6.1185, 'learning_rate': 8.590476190476191e-06, 'epoch': 0.86}\n",
      "{'loss': 8.415, 'learning_rate': 8.582857142857144e-06, 'epoch': 0.87}\n",
      "{'loss': 9.0639, 'learning_rate': 8.575238095238097e-06, 'epoch': 0.87}\n",
      "{'loss': 7.8565, 'learning_rate': 8.567619047619048e-06, 'epoch': 0.87}\n",
      "{'loss': 9.6165, 'learning_rate': 8.560000000000001e-06, 'epoch': 0.88}\n",
      "{'loss': 7.5376, 'learning_rate': 8.552380952380954e-06, 'epoch': 0.88}\n",
      "{'loss': 7.437, 'learning_rate': 8.544761904761905e-06, 'epoch': 0.88}\n",
      "{'loss': 8.028, 'learning_rate': 8.537142857142858e-06, 'epoch': 0.89}\n",
      "{'loss': 7.1385, 'learning_rate': 8.529523809523809e-06, 'epoch': 0.89}\n",
      "{'loss': 7.8265, 'learning_rate': 8.521904761904762e-06, 'epoch': 0.89}\n",
      "{'loss': 7.8551, 'learning_rate': 8.514285714285715e-06, 'epoch': 0.9}\n",
      "{'loss': 6.9859, 'learning_rate': 8.506666666666668e-06, 'epoch': 0.9}\n",
      "{'loss': 7.5814, 'learning_rate': 8.49904761904762e-06, 'epoch': 0.91}\n",
      "{'loss': 7.4725, 'learning_rate': 8.491428571428572e-06, 'epoch': 0.91}\n",
      "{'loss': 5.6822, 'learning_rate': 8.483809523809525e-06, 'epoch': 0.91}\n",
      "{'loss': 5.7788, 'learning_rate': 8.476190476190477e-06, 'epoch': 0.92}\n",
      "{'loss': 7.1385, 'learning_rate': 8.468571428571429e-06, 'epoch': 0.92}\n",
      "{'loss': 6.0206, 'learning_rate': 8.460952380952381e-06, 'epoch': 0.92}\n",
      "{'loss': 6.2397, 'learning_rate': 8.453333333333334e-06, 'epoch': 0.93}\n",
      "{'loss': 5.1176, 'learning_rate': 8.445714285714285e-06, 'epoch': 0.93}\n",
      "{'loss': 5.9426, 'learning_rate': 8.438095238095238e-06, 'epoch': 0.93}\n",
      "{'loss': 5.1424, 'learning_rate': 8.430476190476191e-06, 'epoch': 0.94}\n",
      "{'loss': 4.9533, 'learning_rate': 8.422857142857144e-06, 'epoch': 0.94}\n",
      "{'loss': 5.3883, 'learning_rate': 8.415238095238097e-06, 'epoch': 0.95}\n",
      "{'loss': 5.7484, 'learning_rate': 8.407619047619048e-06, 'epoch': 0.95}\n",
      "{'loss': 6.3932, 'learning_rate': 8.400000000000001e-06, 'epoch': 0.95}\n",
      "{'loss': 5.5908, 'learning_rate': 8.392380952380954e-06, 'epoch': 0.96}\n",
      "{'loss': 5.6742, 'learning_rate': 8.384761904761905e-06, 'epoch': 0.96}\n",
      "{'loss': 4.2229, 'learning_rate': 8.377142857142858e-06, 'epoch': 0.96}\n",
      "{'loss': 5.3745, 'learning_rate': 8.36952380952381e-06, 'epoch': 0.97}\n",
      "{'loss': 5.6186, 'learning_rate': 8.361904761904762e-06, 'epoch': 0.97}\n",
      "{'loss': 5.3621, 'learning_rate': 8.354285714285715e-06, 'epoch': 0.98}\n",
      "{'loss': 4.5324, 'learning_rate': 8.346666666666668e-06, 'epoch': 0.98}\n",
      "{'loss': 5.0265, 'learning_rate': 8.33904761904762e-06, 'epoch': 0.98}\n",
      "{'loss': 4.8258, 'learning_rate': 8.331428571428573e-06, 'epoch': 0.99}\n",
      "{'loss': 5.2537, 'learning_rate': 8.323809523809524e-06, 'epoch': 0.99}\n",
      "{'loss': 4.4538, 'learning_rate': 8.316190476190477e-06, 'epoch': 0.99}\n",
      "{'loss': 10.6027, 'learning_rate': 8.308571428571428e-06, 'epoch': 1.0}\n",
      "{'loss': 4.0161, 'learning_rate': 8.300952380952381e-06, 'epoch': 1.0}\n",
      "{'loss': 6.7771, 'learning_rate': 8.293333333333334e-06, 'epoch': 1.0}\n",
      "{'loss': 6.4071, 'learning_rate': 8.285714285714287e-06, 'epoch': 1.01}\n",
      "{'loss': 3.941, 'learning_rate': 8.278095238095238e-06, 'epoch': 1.01}\n",
      "{'loss': 5.031, 'learning_rate': 8.270476190476191e-06, 'epoch': 1.02}\n",
      "{'loss': 4.8452, 'learning_rate': 8.262857142857144e-06, 'epoch': 1.02}\n",
      "{'loss': 3.8128, 'learning_rate': 8.255238095238097e-06, 'epoch': 1.02}\n",
      "{'loss': 7.2521, 'learning_rate': 8.24761904761905e-06, 'epoch': 1.03}\n",
      "{'loss': 4.0188, 'learning_rate': 8.24e-06, 'epoch': 1.03}\n",
      "{'loss': 4.858, 'learning_rate': 8.232380952380954e-06, 'epoch': 1.03}\n",
      "{'loss': 3.5607, 'learning_rate': 8.224761904761905e-06, 'epoch': 1.04}\n",
      "{'loss': 3.907, 'learning_rate': 8.217142857142858e-06, 'epoch': 1.04}\n",
      "{'loss': 3.5362, 'learning_rate': 8.20952380952381e-06, 'epoch': 1.04}\n",
      "{'loss': 4.0551, 'learning_rate': 8.201904761904762e-06, 'epoch': 1.05}\n",
      "{'loss': 5.7265, 'learning_rate': 8.194285714285714e-06, 'epoch': 1.05}\n",
      "{'loss': 4.3023, 'learning_rate': 8.186666666666667e-06, 'epoch': 1.06}\n",
      "{'loss': 4.9493, 'learning_rate': 8.17904761904762e-06, 'epoch': 1.06}\n",
      "{'loss': 3.9131, 'learning_rate': 8.171428571428573e-06, 'epoch': 1.06}\n",
      "{'loss': 4.28, 'learning_rate': 8.163809523809524e-06, 'epoch': 1.07}\n",
      "{'loss': 4.4252, 'learning_rate': 8.156190476190477e-06, 'epoch': 1.07}\n",
      "{'loss': 4.8075, 'learning_rate': 8.148571428571428e-06, 'epoch': 1.07}\n",
      "{'loss': 3.7079, 'learning_rate': 8.140952380952381e-06, 'epoch': 1.08}\n",
      "{'loss': 3.9827, 'learning_rate': 8.133333333333334e-06, 'epoch': 1.08}\n",
      "{'loss': 3.7386, 'learning_rate': 8.125714285714287e-06, 'epoch': 1.09}\n",
      "{'loss': 3.7449, 'learning_rate': 8.118095238095238e-06, 'epoch': 1.09}\n",
      "{'loss': 3.7912, 'learning_rate': 8.11047619047619e-06, 'epoch': 1.09}\n",
      "{'loss': 3.7567, 'learning_rate': 8.102857142857144e-06, 'epoch': 1.1}\n",
      "{'loss': 3.4613, 'learning_rate': 8.095238095238097e-06, 'epoch': 1.1}\n",
      "{'loss': 4.3195, 'learning_rate': 8.08761904761905e-06, 'epoch': 1.1}\n",
      "{'loss': 3.0707, 'learning_rate': 8.08e-06, 'epoch': 1.11}\n",
      "{'loss': 4.8391, 'learning_rate': 8.072380952380953e-06, 'epoch': 1.11}\n",
      "{'loss': 4.2971, 'learning_rate': 8.064761904761905e-06, 'epoch': 1.11}\n",
      "{'loss': 2.7939, 'learning_rate': 8.057142857142857e-06, 'epoch': 1.12}\n",
      "{'loss': 4.179, 'learning_rate': 8.04952380952381e-06, 'epoch': 1.12}\n",
      "{'loss': 3.8411, 'learning_rate': 8.041904761904763e-06, 'epoch': 1.13}\n",
      "{'loss': 3.2136, 'learning_rate': 8.034285714285714e-06, 'epoch': 1.13}\n",
      "{'loss': 3.4779, 'learning_rate': 8.026666666666667e-06, 'epoch': 1.13}\n",
      "{'loss': 3.8217, 'learning_rate': 8.01904761904762e-06, 'epoch': 1.14}\n",
      "{'loss': 3.5856, 'learning_rate': 8.011428571428573e-06, 'epoch': 1.14}\n",
      "{'loss': 3.6753, 'learning_rate': 8.003809523809524e-06, 'epoch': 1.14}\n",
      "{'loss': 2.5624, 'learning_rate': 7.996190476190477e-06, 'epoch': 1.15}\n",
      "{'loss': 3.5149, 'learning_rate': 7.988571428571428e-06, 'epoch': 1.15}\n",
      "{'loss': 4.7905, 'learning_rate': 7.980952380952381e-06, 'epoch': 1.15}\n",
      "{'loss': 3.4731, 'learning_rate': 7.973333333333334e-06, 'epoch': 1.16}\n",
      "{'loss': 3.992, 'learning_rate': 7.965714285714287e-06, 'epoch': 1.16}\n",
      "{'loss': 4.1871, 'learning_rate': 7.95809523809524e-06, 'epoch': 1.17}\n",
      "{'loss': 4.2156, 'learning_rate': 7.95047619047619e-06, 'epoch': 1.17}\n",
      "{'loss': 3.9254, 'learning_rate': 7.942857142857144e-06, 'epoch': 1.17}\n",
      "{'loss': 3.5761, 'learning_rate': 7.935238095238096e-06, 'epoch': 1.18}\n",
      "{'loss': 3.7809, 'learning_rate': 7.92761904761905e-06, 'epoch': 1.18}\n",
      "{'loss': 4.7248, 'learning_rate': 7.92e-06, 'epoch': 1.18}\n",
      "{'loss': 2.5618, 'learning_rate': 7.912380952380953e-06, 'epoch': 1.19}\n",
      "{'loss': 3.1794, 'learning_rate': 7.904761904761904e-06, 'epoch': 1.19}\n",
      "{'loss': 3.3259, 'learning_rate': 7.897142857142857e-06, 'epoch': 1.2}\n",
      "{'loss': 3.2592, 'learning_rate': 7.88952380952381e-06, 'epoch': 1.2}\n",
      "{'loss': 3.3914, 'learning_rate': 7.881904761904763e-06, 'epoch': 1.2}\n",
      "{'loss': 2.9019, 'learning_rate': 7.874285714285716e-06, 'epoch': 1.21}\n",
      "{'loss': 3.1518, 'learning_rate': 7.866666666666667e-06, 'epoch': 1.21}\n",
      "{'loss': 3.4305, 'learning_rate': 7.85904761904762e-06, 'epoch': 1.21}\n",
      "{'loss': 3.1874, 'learning_rate': 7.851428571428573e-06, 'epoch': 1.22}\n",
      "{'loss': 3.4677, 'learning_rate': 7.843809523809524e-06, 'epoch': 1.22}\n",
      "{'loss': 3.4552, 'learning_rate': 7.836190476190477e-06, 'epoch': 1.22}\n",
      "{'loss': 3.743, 'learning_rate': 7.828571428571428e-06, 'epoch': 1.23}\n",
      "{'loss': 3.213, 'learning_rate': 7.82095238095238e-06, 'epoch': 1.23}\n",
      "{'loss': 3.2812, 'learning_rate': 7.813333333333334e-06, 'epoch': 1.24}\n",
      "{'loss': 3.1942, 'learning_rate': 7.805714285714286e-06, 'epoch': 1.24}\n",
      "{'loss': 3.8108, 'learning_rate': 7.79809523809524e-06, 'epoch': 1.24}\n",
      "{'loss': 3.8609, 'learning_rate': 7.790476190476192e-06, 'epoch': 1.25}\n",
      "{'loss': 3.1532, 'learning_rate': 7.782857142857143e-06, 'epoch': 1.25}\n",
      "{'loss': 3.1092, 'learning_rate': 7.775238095238096e-06, 'epoch': 1.25}\n",
      "{'loss': 2.7736, 'learning_rate': 7.767619047619049e-06, 'epoch': 1.26}\n",
      "{'loss': 2.8666, 'learning_rate': 7.76e-06, 'epoch': 1.26}\n",
      "{'loss': 3.1982, 'learning_rate': 7.752380952380953e-06, 'epoch': 1.26}\n",
      "{'loss': 3.3483, 'learning_rate': 7.744761904761904e-06, 'epoch': 1.27}\n",
      "{'loss': 2.7389, 'learning_rate': 7.737142857142857e-06, 'epoch': 1.27}\n",
      "{'loss': 3.0266, 'learning_rate': 7.72952380952381e-06, 'epoch': 1.28}\n",
      "{'loss': 3.32, 'learning_rate': 7.721904761904763e-06, 'epoch': 1.28}\n",
      "{'loss': 3.5108, 'learning_rate': 7.714285714285716e-06, 'epoch': 1.28}\n",
      "{'loss': 2.9807, 'learning_rate': 7.706666666666669e-06, 'epoch': 1.29}\n",
      "{'loss': 3.8458, 'learning_rate': 7.69904761904762e-06, 'epoch': 1.29}\n",
      "{'loss': 3.0104, 'learning_rate': 7.691428571428573e-06, 'epoch': 1.29}\n",
      "{'loss': 3.1457, 'learning_rate': 7.683809523809524e-06, 'epoch': 1.3}\n",
      "{'loss': 4.0398, 'learning_rate': 7.676190476190477e-06, 'epoch': 1.3}\n",
      "{'loss': 3.1978, 'learning_rate': 7.66857142857143e-06, 'epoch': 1.31}\n",
      "{'loss': 2.9519, 'learning_rate': 7.66095238095238e-06, 'epoch': 1.31}\n",
      "{'loss': 2.3795, 'learning_rate': 7.653333333333333e-06, 'epoch': 1.31}\n",
      "{'loss': 3.5787, 'learning_rate': 7.645714285714286e-06, 'epoch': 1.32}\n",
      "{'loss': 3.3431, 'learning_rate': 7.63809523809524e-06, 'epoch': 1.32}\n",
      "{'loss': 2.8294, 'learning_rate': 7.630476190476192e-06, 'epoch': 1.32}\n",
      "{'loss': 2.928, 'learning_rate': 7.622857142857143e-06, 'epoch': 1.33}\n",
      "{'loss': 3.7055, 'learning_rate': 7.615238095238095e-06, 'epoch': 1.33}\n",
      "{'loss': 3.7848, 'learning_rate': 7.607619047619048e-06, 'epoch': 1.33}\n",
      "{'loss': 2.5605, 'learning_rate': 7.600000000000001e-06, 'epoch': 1.34}\n",
      "{'loss': 3.3677, 'learning_rate': 7.592380952380953e-06, 'epoch': 1.34}\n",
      "{'loss': 3.0777, 'learning_rate': 7.584761904761906e-06, 'epoch': 1.35}\n",
      "{'loss': 3.9458, 'learning_rate': 7.577142857142857e-06, 'epoch': 1.35}\n",
      "{'loss': 2.9924, 'learning_rate': 7.56952380952381e-06, 'epoch': 1.35}\n",
      "{'loss': 3.0728, 'learning_rate': 7.561904761904763e-06, 'epoch': 1.36}\n",
      "{'loss': 2.3473, 'learning_rate': 7.5542857142857155e-06, 'epoch': 1.36}\n",
      "{'loss': 3.2645, 'learning_rate': 7.5466666666666675e-06, 'epoch': 1.36}\n",
      "{'loss': 2.7399, 'learning_rate': 7.5390476190476195e-06, 'epoch': 1.37}\n",
      "{'loss': 2.4969, 'learning_rate': 7.5314285714285716e-06, 'epoch': 1.37}\n",
      "{'loss': 3.4735, 'learning_rate': 7.523809523809524e-06, 'epoch': 1.37}\n",
      "{'loss': 3.3288, 'learning_rate': 7.516190476190477e-06, 'epoch': 1.38}\n",
      "{'loss': 3.1156, 'learning_rate': 7.508571428571429e-06, 'epoch': 1.38}\n",
      "{'loss': 3.3039, 'learning_rate': 7.500952380952382e-06, 'epoch': 1.39}\n",
      "{'loss': 3.4712, 'learning_rate': 7.493333333333333e-06, 'epoch': 1.39}\n",
      "{'loss': 2.6814, 'learning_rate': 7.485714285714286e-06, 'epoch': 1.39}\n",
      "{'loss': 3.7548, 'learning_rate': 7.478095238095239e-06, 'epoch': 1.4}\n",
      "{'loss': 3.369, 'learning_rate': 7.470476190476191e-06, 'epoch': 1.4}\n",
      "{'loss': 2.8178, 'learning_rate': 7.462857142857144e-06, 'epoch': 1.4}\n",
      "{'loss': 3.1673, 'learning_rate': 7.455238095238095e-06, 'epoch': 1.41}\n",
      "{'loss': 2.135, 'learning_rate': 7.447619047619048e-06, 'epoch': 1.41}\n",
      "{'loss': 2.4928, 'learning_rate': 7.440000000000001e-06, 'epoch': 1.42}\n",
      "{'loss': 3.3339, 'learning_rate': 7.432380952380953e-06, 'epoch': 1.42}\n",
      "{'loss': 2.7785, 'learning_rate': 7.424761904761906e-06, 'epoch': 1.42}\n",
      "{'loss': 2.9405, 'learning_rate': 7.417142857142857e-06, 'epoch': 1.43}\n",
      "{'loss': 2.998, 'learning_rate': 7.40952380952381e-06, 'epoch': 1.43}\n",
      "{'loss': 4.5106, 'learning_rate': 7.4019047619047625e-06, 'epoch': 1.43}\n",
      "{'loss': 2.8525, 'learning_rate': 7.394285714285715e-06, 'epoch': 1.44}\n",
      "{'loss': 2.802, 'learning_rate': 7.386666666666667e-06, 'epoch': 1.44}\n",
      "{'loss': 3.5186, 'learning_rate': 7.37904761904762e-06, 'epoch': 1.44}\n",
      "{'loss': 3.4175, 'learning_rate': 7.371428571428571e-06, 'epoch': 1.45}\n",
      "{'loss': 3.4941, 'learning_rate': 7.363809523809524e-06, 'epoch': 1.45}\n",
      "{'loss': 2.7236, 'learning_rate': 7.356190476190477e-06, 'epoch': 1.46}\n",
      "{'loss': 3.6074, 'learning_rate': 7.348571428571429e-06, 'epoch': 1.46}\n",
      "{'loss': 2.914, 'learning_rate': 7.340952380952382e-06, 'epoch': 1.46}\n",
      "{'loss': 2.9999, 'learning_rate': 7.333333333333333e-06, 'epoch': 1.47}\n",
      "{'loss': 3.2525, 'learning_rate': 7.325714285714286e-06, 'epoch': 1.47}\n",
      "{'loss': 2.4409, 'learning_rate': 7.318095238095239e-06, 'epoch': 1.47}\n",
      "{'loss': 2.7692, 'learning_rate': 7.310476190476191e-06, 'epoch': 1.48}\n",
      "{'loss': 3.2981, 'learning_rate': 7.302857142857144e-06, 'epoch': 1.48}\n",
      "{'loss': 3.1372, 'learning_rate': 7.295238095238097e-06, 'epoch': 1.48}\n",
      "{'loss': 3.6115, 'learning_rate': 7.287619047619048e-06, 'epoch': 1.49}\n",
      "{'loss': 2.4744, 'learning_rate': 7.280000000000001e-06, 'epoch': 1.49}\n",
      "{'loss': 2.4641, 'learning_rate': 7.272380952380953e-06, 'epoch': 1.5}\n",
      "{'loss': 5.2018, 'learning_rate': 7.2647619047619055e-06, 'epoch': 1.5}\n",
      "{'loss': 2.5752, 'learning_rate': 7.257142857142858e-06, 'epoch': 1.5}\n",
      "{'loss': 1.9866, 'learning_rate': 7.2495238095238095e-06, 'epoch': 1.51}\n",
      "{'loss': 2.988, 'learning_rate': 7.241904761904762e-06, 'epoch': 1.51}\n",
      "{'loss': 2.7988, 'learning_rate': 7.234285714285715e-06, 'epoch': 1.51}\n",
      "{'loss': 2.7318, 'learning_rate': 7.226666666666667e-06, 'epoch': 1.52}\n",
      "{'loss': 2.4942, 'learning_rate': 7.21904761904762e-06, 'epoch': 1.52}\n",
      "{'loss': 2.8379, 'learning_rate': 7.211428571428573e-06, 'epoch': 1.53}\n",
      "{'loss': 2.6176, 'learning_rate': 7.203809523809524e-06, 'epoch': 1.53}\n",
      "{'loss': 2.7965, 'learning_rate': 7.196190476190477e-06, 'epoch': 1.53}\n",
      "{'loss': 3.1332, 'learning_rate': 7.188571428571429e-06, 'epoch': 1.54}\n",
      "{'loss': 2.816, 'learning_rate': 7.180952380952382e-06, 'epoch': 1.54}\n",
      "{'loss': 2.2307, 'learning_rate': 7.173333333333335e-06, 'epoch': 1.54}\n",
      "{'loss': 2.8132, 'learning_rate': 7.165714285714286e-06, 'epoch': 1.55}\n",
      "{'loss': 2.6337, 'learning_rate': 7.158095238095239e-06, 'epoch': 1.55}\n",
      "{'loss': 2.5918, 'learning_rate': 7.150476190476191e-06, 'epoch': 1.55}\n",
      "{'loss': 3.066, 'learning_rate': 7.1428571428571436e-06, 'epoch': 1.56}\n",
      "{'loss': 2.8688, 'learning_rate': 7.135238095238096e-06, 'epoch': 1.56}\n",
      "{'loss': 2.6139, 'learning_rate': 7.127619047619048e-06, 'epoch': 1.57}\n",
      "{'loss': 1.9545, 'learning_rate': 7.1200000000000004e-06, 'epoch': 1.57}\n",
      "{'loss': 2.7146, 'learning_rate': 7.1123809523809525e-06, 'epoch': 1.57}\n",
      "{'loss': 2.5697, 'learning_rate': 7.104761904761905e-06, 'epoch': 1.58}\n",
      "{'loss': 3.3904, 'learning_rate': 7.097142857142858e-06, 'epoch': 1.58}\n",
      "{'loss': 3.0068, 'learning_rate': 7.08952380952381e-06, 'epoch': 1.58}\n",
      "{'loss': 2.4983, 'learning_rate': 7.081904761904762e-06, 'epoch': 1.59}\n",
      "{'loss': 2.6728, 'learning_rate': 7.074285714285715e-06, 'epoch': 1.59}\n",
      "{'loss': 2.8268, 'learning_rate': 7.066666666666667e-06, 'epoch': 1.59}\n",
      "{'loss': 2.3457, 'learning_rate': 7.05904761904762e-06, 'epoch': 1.6}\n",
      "{'loss': 2.66, 'learning_rate': 7.051428571428573e-06, 'epoch': 1.6}\n",
      "{'loss': 3.043, 'learning_rate': 7.043809523809524e-06, 'epoch': 1.61}\n",
      "{'loss': 2.6205, 'learning_rate': 7.036190476190477e-06, 'epoch': 1.61}\n",
      "{'loss': 2.5906, 'learning_rate': 7.028571428571429e-06, 'epoch': 1.61}\n",
      "{'loss': 2.5704, 'learning_rate': 7.020952380952382e-06, 'epoch': 1.62}\n",
      "{'loss': 3.2534, 'learning_rate': 7.0133333333333345e-06, 'epoch': 1.62}\n",
      "{'loss': 2.8432, 'learning_rate': 7.0057142857142865e-06, 'epoch': 1.62}\n",
      "{'loss': 2.6358, 'learning_rate': 6.9980952380952385e-06, 'epoch': 1.63}\n",
      "{'loss': 2.4913, 'learning_rate': 6.9904761904761905e-06, 'epoch': 1.63}\n",
      "{'loss': 2.9323, 'learning_rate': 6.982857142857143e-06, 'epoch': 1.64}\n",
      "{'loss': 3.4934, 'learning_rate': 6.975238095238096e-06, 'epoch': 1.64}\n",
      "{'loss': 3.0541, 'learning_rate': 6.967619047619048e-06, 'epoch': 1.64}\n",
      "{'loss': 2.5126, 'learning_rate': 6.96e-06, 'epoch': 1.65}\n",
      "{'loss': 3.1811, 'learning_rate': 6.952380952380952e-06, 'epoch': 1.65}\n",
      "{'loss': 2.7578, 'learning_rate': 6.944761904761905e-06, 'epoch': 1.65}\n",
      "{'loss': 2.9179, 'learning_rate': 6.937142857142858e-06, 'epoch': 1.66}\n",
      "{'loss': 2.1785, 'learning_rate': 6.92952380952381e-06, 'epoch': 1.66}\n",
      "{'loss': 3.2981, 'learning_rate': 6.921904761904763e-06, 'epoch': 1.66}\n",
      "{'loss': 2.3691, 'learning_rate': 6.914285714285715e-06, 'epoch': 1.67}\n",
      "{'loss': 2.5607, 'learning_rate': 6.906666666666667e-06, 'epoch': 1.67}\n",
      "{'loss': 2.354, 'learning_rate': 6.89904761904762e-06, 'epoch': 1.68}\n",
      "{'loss': 2.5758, 'learning_rate': 6.891428571428573e-06, 'epoch': 1.68}\n",
      "{'loss': 2.5202, 'learning_rate': 6.883809523809525e-06, 'epoch': 1.68}\n",
      "{'loss': 2.1257, 'learning_rate': 6.876190476190477e-06, 'epoch': 1.69}\n",
      "{'loss': 2.4814, 'learning_rate': 6.868571428571429e-06, 'epoch': 1.69}\n",
      "{'loss': 2.4798, 'learning_rate': 6.8609523809523815e-06, 'epoch': 1.69}\n",
      "{'loss': 2.2469, 'learning_rate': 6.853333333333334e-06, 'epoch': 1.7}\n",
      "{'loss': 2.6918, 'learning_rate': 6.845714285714286e-06, 'epoch': 1.7}\n",
      "{'loss': 2.7772, 'learning_rate': 6.838095238095238e-06, 'epoch': 1.7}\n",
      "{'loss': 2.1579, 'learning_rate': 6.83047619047619e-06, 'epoch': 1.71}\n",
      "{'loss': 2.6796, 'learning_rate': 6.822857142857143e-06, 'epoch': 1.71}\n",
      "{'loss': 2.5666, 'learning_rate': 6.815238095238096e-06, 'epoch': 1.72}\n",
      "{'loss': 2.097, 'learning_rate': 6.807619047619048e-06, 'epoch': 1.72}\n",
      "{'loss': 2.6079, 'learning_rate': 6.800000000000001e-06, 'epoch': 1.72}\n",
      "{'loss': 2.7249, 'learning_rate': 6.792380952380952e-06, 'epoch': 1.73}\n",
      "{'loss': 2.702, 'learning_rate': 6.784761904761905e-06, 'epoch': 1.73}\n",
      "{'loss': 2.9206, 'learning_rate': 6.777142857142858e-06, 'epoch': 1.73}\n",
      "{'loss': 3.2566, 'learning_rate': 6.769523809523811e-06, 'epoch': 1.74}\n",
      "{'loss': 2.3405, 'learning_rate': 6.761904761904763e-06, 'epoch': 1.74}\n",
      "{'loss': 2.748, 'learning_rate': 6.754285714285715e-06, 'epoch': 1.75}\n",
      "{'loss': 2.2789, 'learning_rate': 6.746666666666667e-06, 'epoch': 1.75}\n",
      "{'loss': 2.6847, 'learning_rate': 6.73904761904762e-06, 'epoch': 1.75}\n",
      "{'loss': 2.7078, 'learning_rate': 6.7314285714285724e-06, 'epoch': 1.76}\n",
      "{'loss': 3.4186, 'learning_rate': 6.7238095238095245e-06, 'epoch': 1.76}\n",
      "{'loss': 2.3452, 'learning_rate': 6.716190476190477e-06, 'epoch': 1.76}\n",
      "{'loss': 2.6985, 'learning_rate': 6.7085714285714285e-06, 'epoch': 1.77}\n",
      "{'loss': 2.4913, 'learning_rate': 6.700952380952381e-06, 'epoch': 1.77}\n",
      "{'loss': 3.0671, 'learning_rate': 6.693333333333334e-06, 'epoch': 1.77}\n",
      "{'loss': 2.7408, 'learning_rate': 6.685714285714286e-06, 'epoch': 1.78}\n",
      "{'loss': 2.4085, 'learning_rate': 6.678095238095239e-06, 'epoch': 1.78}\n",
      "{'loss': 2.1903, 'learning_rate': 6.67047619047619e-06, 'epoch': 1.79}\n",
      "{'loss': 2.8315, 'learning_rate': 6.662857142857143e-06, 'epoch': 1.79}\n",
      "{'loss': 2.2974, 'learning_rate': 6.655238095238096e-06, 'epoch': 1.79}\n",
      "{'loss': 3.0714, 'learning_rate': 6.647619047619048e-06, 'epoch': 1.8}\n",
      "{'loss': 2.5291, 'learning_rate': 6.640000000000001e-06, 'epoch': 1.8}\n",
      "{'loss': 2.0649, 'learning_rate': 6.632380952380954e-06, 'epoch': 1.8}\n",
      "{'loss': 2.3144, 'learning_rate': 6.624761904761905e-06, 'epoch': 1.81}\n",
      "{'loss': 2.675, 'learning_rate': 6.617142857142858e-06, 'epoch': 1.81}\n",
      "{'loss': 2.2778, 'learning_rate': 6.6095238095238105e-06, 'epoch': 1.81}\n",
      "{'loss': 3.1218, 'learning_rate': 6.6019047619047625e-06, 'epoch': 1.82}\n",
      "{'loss': 2.4283, 'learning_rate': 6.594285714285715e-06, 'epoch': 1.82}\n",
      "{'loss': 2.5488, 'learning_rate': 6.5866666666666666e-06, 'epoch': 1.83}\n",
      "{'loss': 2.6142, 'learning_rate': 6.579047619047619e-06, 'epoch': 1.83}\n",
      "{'loss': 2.8729, 'learning_rate': 6.571428571428572e-06, 'epoch': 1.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HOME\\anaconda3\\lib\\site-packages\\peft\\utils\\save_and_load.py:168: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.453, 'learning_rate': 6.563809523809524e-06, 'epoch': 1.84}\n",
      "{'loss': 2.266, 'learning_rate': 6.556190476190477e-06, 'epoch': 1.84}\n",
      "{'loss': 2.8717, 'learning_rate': 6.548571428571428e-06, 'epoch': 1.84}\n",
      "{'loss': 2.9585, 'learning_rate': 6.540952380952381e-06, 'epoch': 1.85}\n",
      "{'loss': 2.9462, 'learning_rate': 6.533333333333334e-06, 'epoch': 1.85}\n",
      "{'loss': 2.3393, 'learning_rate': 6.525714285714286e-06, 'epoch': 1.86}\n",
      "{'loss': 1.9945, 'learning_rate': 6.518095238095239e-06, 'epoch': 1.86}\n",
      "{'loss': 2.741, 'learning_rate': 6.510476190476192e-06, 'epoch': 1.86}\n",
      "{'loss': 2.1419, 'learning_rate': 6.502857142857143e-06, 'epoch': 1.87}\n",
      "{'loss': 2.4419, 'learning_rate': 6.495238095238096e-06, 'epoch': 1.87}\n",
      "{'loss': 2.4509, 'learning_rate': 6.487619047619048e-06, 'epoch': 1.87}\n",
      "{'loss': 2.4911, 'learning_rate': 6.480000000000001e-06, 'epoch': 1.88}\n",
      "{'loss': 2.1605, 'learning_rate': 6.4723809523809535e-06, 'epoch': 1.88}\n",
      "{'loss': 2.5204, 'learning_rate': 6.464761904761905e-06, 'epoch': 1.88}\n",
      "{'loss': 2.0268, 'learning_rate': 6.4571428571428575e-06, 'epoch': 1.89}\n",
      "{'loss': 2.8355, 'learning_rate': 6.44952380952381e-06, 'epoch': 1.89}\n",
      "{'loss': 2.9172, 'learning_rate': 6.441904761904762e-06, 'epoch': 1.9}\n",
      "{'loss': 2.9139, 'learning_rate': 6.434285714285715e-06, 'epoch': 1.9}\n",
      "{'loss': 2.6607, 'learning_rate': 6.426666666666668e-06, 'epoch': 1.9}\n",
      "{'loss': 2.4807, 'learning_rate': 6.419047619047619e-06, 'epoch': 1.91}\n",
      "{'loss': 2.715, 'learning_rate': 6.411428571428572e-06, 'epoch': 1.91}\n",
      "{'loss': 2.3872, 'learning_rate': 6.403809523809524e-06, 'epoch': 1.91}\n",
      "{'loss': 2.6927, 'learning_rate': 6.396190476190477e-06, 'epoch': 1.92}\n",
      "{'loss': 2.2615, 'learning_rate': 6.38857142857143e-06, 'epoch': 1.92}\n",
      "{'loss': 2.3134, 'learning_rate': 6.380952380952381e-06, 'epoch': 1.92}\n",
      "{'loss': 2.8163, 'learning_rate': 6.373333333333334e-06, 'epoch': 1.93}\n",
      "{'loss': 2.1976, 'learning_rate': 6.365714285714286e-06, 'epoch': 1.93}\n",
      "{'loss': 3.0141, 'learning_rate': 6.358095238095239e-06, 'epoch': 1.94}\n",
      "{'loss': 2.4874, 'learning_rate': 6.350476190476192e-06, 'epoch': 1.94}\n",
      "{'loss': 2.302, 'learning_rate': 6.342857142857143e-06, 'epoch': 1.94}\n",
      "{'loss': 2.2209, 'learning_rate': 6.335238095238096e-06, 'epoch': 1.95}\n",
      "{'loss': 2.7289, 'learning_rate': 6.327619047619048e-06, 'epoch': 1.95}\n",
      "{'loss': 1.8999, 'learning_rate': 6.3200000000000005e-06, 'epoch': 1.95}\n",
      "{'loss': 2.7656, 'learning_rate': 6.312380952380953e-06, 'epoch': 1.96}\n",
      "{'loss': 2.5276, 'learning_rate': 6.304761904761905e-06, 'epoch': 1.96}\n",
      "{'loss': 2.8198, 'learning_rate': 6.297142857142857e-06, 'epoch': 1.97}\n",
      "{'loss': 2.4286, 'learning_rate': 6.28952380952381e-06, 'epoch': 1.97}\n",
      "{'loss': 2.5808, 'learning_rate': 6.281904761904762e-06, 'epoch': 1.97}\n",
      "{'loss': 2.325, 'learning_rate': 6.274285714285715e-06, 'epoch': 1.98}\n",
      "{'loss': 3.0626, 'learning_rate': 6.266666666666668e-06, 'epoch': 1.98}\n",
      "{'loss': 2.5117, 'learning_rate': 6.259047619047619e-06, 'epoch': 1.98}\n",
      "{'loss': 2.5866, 'learning_rate': 6.251428571428572e-06, 'epoch': 1.99}\n",
      "{'loss': 3.0021, 'learning_rate': 6.243809523809524e-06, 'epoch': 1.99}\n",
      "{'loss': 2.1233, 'learning_rate': 6.236190476190477e-06, 'epoch': 1.99}\n",
      "{'loss': 2.9662, 'learning_rate': 6.22857142857143e-06, 'epoch': 2.0}\n",
      "{'loss': 1.8466, 'learning_rate': 6.220952380952382e-06, 'epoch': 2.0}\n",
      "{'loss': 2.4241, 'learning_rate': 6.213333333333334e-06, 'epoch': 2.01}\n",
      "{'loss': 2.2725, 'learning_rate': 6.205714285714286e-06, 'epoch': 2.01}\n",
      "{'loss': 2.4539, 'learning_rate': 6.1980952380952386e-06, 'epoch': 2.01}\n",
      "{'loss': 2.7163, 'learning_rate': 6.1904761904761914e-06, 'epoch': 2.02}\n",
      "{'loss': 2.8133, 'learning_rate': 6.1828571428571434e-06, 'epoch': 2.02}\n",
      "{'loss': 1.9855, 'learning_rate': 6.1752380952380954e-06, 'epoch': 2.02}\n",
      "{'loss': 2.505, 'learning_rate': 6.1676190476190475e-06, 'epoch': 2.03}\n",
      "{'loss': 2.964, 'learning_rate': 6.16e-06, 'epoch': 2.03}\n",
      "{'loss': 2.5438, 'learning_rate': 6.152380952380953e-06, 'epoch': 2.03}\n",
      "{'loss': 2.2539, 'learning_rate': 6.144761904761905e-06, 'epoch': 2.04}\n",
      "{'loss': 2.7616, 'learning_rate': 6.137142857142858e-06, 'epoch': 2.04}\n",
      "{'loss': 2.1032, 'learning_rate': 6.12952380952381e-06, 'epoch': 2.05}\n",
      "{'loss': 2.0964, 'learning_rate': 6.121904761904762e-06, 'epoch': 2.05}\n",
      "{'loss': 2.5614, 'learning_rate': 6.114285714285715e-06, 'epoch': 2.05}\n",
      "{'loss': 2.9637, 'learning_rate': 6.106666666666668e-06, 'epoch': 2.06}\n",
      "{'loss': 2.3793, 'learning_rate': 6.09904761904762e-06, 'epoch': 2.06}\n",
      "{'loss': 2.1357, 'learning_rate': 6.091428571428572e-06, 'epoch': 2.06}\n",
      "{'loss': 2.7199, 'learning_rate': 6.083809523809524e-06, 'epoch': 2.07}\n",
      "{'loss': 2.4357, 'learning_rate': 6.076190476190477e-06, 'epoch': 2.07}\n",
      "{'loss': 2.3985, 'learning_rate': 6.0685714285714295e-06, 'epoch': 2.08}\n",
      "{'loss': 2.6012, 'learning_rate': 6.0609523809523815e-06, 'epoch': 2.08}\n",
      "{'loss': 2.8399, 'learning_rate': 6.0533333333333335e-06, 'epoch': 2.08}\n",
      "{'loss': 2.0343, 'learning_rate': 6.0457142857142855e-06, 'epoch': 2.09}\n",
      "{'loss': 2.3591, 'learning_rate': 6.038095238095238e-06, 'epoch': 2.09}\n",
      "{'loss': 2.5073, 'learning_rate': 6.030476190476191e-06, 'epoch': 2.09}\n",
      "{'loss': 2.6804, 'learning_rate': 6.022857142857143e-06, 'epoch': 2.1}\n",
      "{'loss': 3.0789, 'learning_rate': 6.015238095238096e-06, 'epoch': 2.1}\n",
      "{'loss': 1.8702, 'learning_rate': 6.007619047619047e-06, 'epoch': 2.1}\n",
      "{'loss': 3.0974, 'learning_rate': 6e-06, 'epoch': 2.11}\n",
      "{'loss': 2.6888, 'learning_rate': 5.992380952380953e-06, 'epoch': 2.11}\n",
      "{'loss': 2.2575, 'learning_rate': 5.984761904761905e-06, 'epoch': 2.12}\n",
      "{'loss': 2.2407, 'learning_rate': 5.977142857142858e-06, 'epoch': 2.12}\n",
      "{'loss': 2.8759, 'learning_rate': 5.96952380952381e-06, 'epoch': 2.12}\n",
      "{'loss': 1.9405, 'learning_rate': 5.961904761904762e-06, 'epoch': 2.13}\n",
      "{'loss': 2.6192, 'learning_rate': 5.954285714285715e-06, 'epoch': 2.13}\n",
      "{'loss': 2.2933, 'learning_rate': 5.946666666666668e-06, 'epoch': 2.13}\n",
      "{'loss': 2.4843, 'learning_rate': 5.93904761904762e-06, 'epoch': 2.14}\n",
      "{'loss': 2.5358, 'learning_rate': 5.9314285714285725e-06, 'epoch': 2.14}\n",
      "{'loss': 2.402, 'learning_rate': 5.923809523809524e-06, 'epoch': 2.14}\n",
      "{'loss': 1.8796, 'learning_rate': 5.9161904761904765e-06, 'epoch': 2.15}\n",
      "{'loss': 2.5791, 'learning_rate': 5.908571428571429e-06, 'epoch': 2.15}\n",
      "{'loss': 1.8488, 'learning_rate': 5.900952380952381e-06, 'epoch': 2.16}\n",
      "{'loss': 1.9837, 'learning_rate': 5.893333333333334e-06, 'epoch': 2.16}\n",
      "{'loss': 2.5015, 'learning_rate': 5.885714285714285e-06, 'epoch': 2.16}\n",
      "{'loss': 1.9296, 'learning_rate': 5.878095238095238e-06, 'epoch': 2.17}\n",
      "{'loss': 2.2906, 'learning_rate': 5.870476190476191e-06, 'epoch': 2.17}\n",
      "{'loss': 1.932, 'learning_rate': 5.862857142857143e-06, 'epoch': 2.17}\n",
      "{'loss': 2.7122, 'learning_rate': 5.855238095238096e-06, 'epoch': 2.18}\n",
      "{'loss': 2.74, 'learning_rate': 5.847619047619049e-06, 'epoch': 2.18}\n",
      "{'loss': 2.6211, 'learning_rate': 5.84e-06, 'epoch': 2.19}\n",
      "{'loss': 2.417, 'learning_rate': 5.832380952380953e-06, 'epoch': 2.19}\n",
      "{'loss': 2.2582, 'learning_rate': 5.824761904761906e-06, 'epoch': 2.19}\n",
      "{'loss': 2.7363, 'learning_rate': 5.817142857142858e-06, 'epoch': 2.2}\n",
      "{'loss': 2.2801, 'learning_rate': 5.8095238095238106e-06, 'epoch': 2.2}\n",
      "{'loss': 2.52, 'learning_rate': 5.801904761904762e-06, 'epoch': 2.2}\n",
      "{'loss': 2.4447, 'learning_rate': 5.794285714285715e-06, 'epoch': 2.21}\n",
      "{'loss': 2.6598, 'learning_rate': 5.7866666666666674e-06, 'epoch': 2.21}\n",
      "{'loss': 2.6726, 'learning_rate': 5.7790476190476195e-06, 'epoch': 2.21}\n",
      "{'loss': 2.6695, 'learning_rate': 5.771428571428572e-06, 'epoch': 2.22}\n",
      "{'loss': 2.4252, 'learning_rate': 5.7638095238095235e-06, 'epoch': 2.22}\n",
      "{'loss': 2.3452, 'learning_rate': 5.756190476190476e-06, 'epoch': 2.23}\n",
      "{'loss': 2.182, 'learning_rate': 5.748571428571429e-06, 'epoch': 2.23}\n",
      "{'loss': 2.2835, 'learning_rate': 5.740952380952381e-06, 'epoch': 2.23}\n",
      "{'loss': 2.4498, 'learning_rate': 5.733333333333334e-06, 'epoch': 2.24}\n",
      "{'loss': 2.7411, 'learning_rate': 5.725714285714287e-06, 'epoch': 2.24}\n",
      "{'loss': 2.4294, 'learning_rate': 5.718095238095238e-06, 'epoch': 2.24}\n",
      "{'loss': 1.5878, 'learning_rate': 5.710476190476191e-06, 'epoch': 2.25}\n",
      "{'loss': 2.0773, 'learning_rate': 5.702857142857143e-06, 'epoch': 2.25}\n",
      "{'loss': 2.0734, 'learning_rate': 5.695238095238096e-06, 'epoch': 2.25}\n",
      "{'loss': 2.0269, 'learning_rate': 5.687619047619049e-06, 'epoch': 2.26}\n",
      "{'loss': 1.7899, 'learning_rate': 5.68e-06, 'epoch': 2.26}\n",
      "{'loss': 1.962, 'learning_rate': 5.672380952380953e-06, 'epoch': 2.27}\n",
      "{'loss': 2.1771, 'learning_rate': 5.6647619047619055e-06, 'epoch': 2.27}\n",
      "{'loss': 2.1489, 'learning_rate': 5.6571428571428576e-06, 'epoch': 2.27}\n",
      "{'loss': 2.2173, 'learning_rate': 5.64952380952381e-06, 'epoch': 2.28}\n",
      "{'loss': 1.7828, 'learning_rate': 5.641904761904763e-06, 'epoch': 2.28}\n",
      "{'loss': 1.7337, 'learning_rate': 5.6342857142857144e-06, 'epoch': 2.28}\n",
      "{'loss': 2.2287, 'learning_rate': 5.626666666666667e-06, 'epoch': 2.29}\n",
      "{'loss': 2.678, 'learning_rate': 5.619047619047619e-06, 'epoch': 2.29}\n",
      "{'loss': 2.0923, 'learning_rate': 5.611428571428572e-06, 'epoch': 2.3}\n",
      "{'loss': 2.7008, 'learning_rate': 5.603809523809525e-06, 'epoch': 2.3}\n",
      "{'loss': 2.6631, 'learning_rate': 5.596190476190476e-06, 'epoch': 2.3}\n",
      "{'loss': 2.5068, 'learning_rate': 5.588571428571429e-06, 'epoch': 2.31}\n",
      "{'loss': 1.8603, 'learning_rate': 5.580952380952381e-06, 'epoch': 2.31}\n",
      "{'loss': 2.4283, 'learning_rate': 5.573333333333334e-06, 'epoch': 2.31}\n",
      "{'loss': 2.0432, 'learning_rate': 5.565714285714287e-06, 'epoch': 2.32}\n",
      "{'loss': 2.5608, 'learning_rate': 5.558095238095239e-06, 'epoch': 2.32}\n",
      "{'loss': 2.1712, 'learning_rate': 5.550476190476191e-06, 'epoch': 2.32}\n",
      "{'loss': 2.1408, 'learning_rate': 5.542857142857143e-06, 'epoch': 2.33}\n",
      "{'loss': 2.7744, 'learning_rate': 5.535238095238096e-06, 'epoch': 2.33}\n",
      "{'loss': 2.2619, 'learning_rate': 5.5276190476190485e-06, 'epoch': 2.34}\n",
      "{'loss': 2.0496, 'learning_rate': 5.5200000000000005e-06, 'epoch': 2.34}\n",
      "{'loss': 2.2038, 'learning_rate': 5.5123809523809525e-06, 'epoch': 2.34}\n",
      "{'loss': 1.9484, 'learning_rate': 5.504761904761905e-06, 'epoch': 2.35}\n",
      "{'loss': 2.0401, 'learning_rate': 5.497142857142857e-06, 'epoch': 2.35}\n",
      "{'loss': 2.2933, 'learning_rate': 5.48952380952381e-06, 'epoch': 2.35}\n",
      "{'loss': 2.1588, 'learning_rate': 5.481904761904763e-06, 'epoch': 2.36}\n",
      "{'loss': 2.6334, 'learning_rate': 5.474285714285714e-06, 'epoch': 2.36}\n",
      "{'loss': 1.9206, 'learning_rate': 5.466666666666667e-06, 'epoch': 2.36}\n",
      "{'loss': 2.3532, 'learning_rate': 5.459047619047619e-06, 'epoch': 2.37}\n",
      "{'loss': 2.4812, 'learning_rate': 5.451428571428572e-06, 'epoch': 2.37}\n",
      "{'loss': 1.9541, 'learning_rate': 5.443809523809525e-06, 'epoch': 2.38}\n",
      "{'loss': 2.2014, 'learning_rate': 5.436190476190477e-06, 'epoch': 2.38}\n",
      "{'loss': 2.3516, 'learning_rate': 5.428571428571429e-06, 'epoch': 2.38}\n",
      "{'loss': 2.0986, 'learning_rate': 5.420952380952381e-06, 'epoch': 2.39}\n",
      "{'loss': 2.1243, 'learning_rate': 5.413333333333334e-06, 'epoch': 2.39}\n",
      "{'loss': 2.1622, 'learning_rate': 5.405714285714287e-06, 'epoch': 2.39}\n",
      "{'loss': 2.0067, 'learning_rate': 5.398095238095239e-06, 'epoch': 2.4}\n",
      "{'loss': 2.1213, 'learning_rate': 5.390476190476191e-06, 'epoch': 2.4}\n",
      "{'loss': 2.8764, 'learning_rate': 5.382857142857143e-06, 'epoch': 2.41}\n",
      "{'loss': 2.2376, 'learning_rate': 5.3752380952380955e-06, 'epoch': 2.41}\n",
      "{'loss': 2.6717, 'learning_rate': 5.367619047619048e-06, 'epoch': 2.41}\n",
      "{'loss': 2.4732, 'learning_rate': 5.36e-06, 'epoch': 2.42}\n",
      "{'loss': 2.5247, 'learning_rate': 5.352380952380953e-06, 'epoch': 2.42}\n",
      "{'loss': 2.0931, 'learning_rate': 5.344761904761905e-06, 'epoch': 2.42}\n",
      "{'loss': 2.4575, 'learning_rate': 5.337142857142857e-06, 'epoch': 2.43}\n",
      "{'loss': 1.9848, 'learning_rate': 5.32952380952381e-06, 'epoch': 2.43}\n",
      "{'loss': 2.6647, 'learning_rate': 5.321904761904763e-06, 'epoch': 2.43}\n",
      "{'loss': 2.703, 'learning_rate': 5.314285714285715e-06, 'epoch': 2.44}\n",
      "{'loss': 2.5995, 'learning_rate': 5.306666666666667e-06, 'epoch': 2.44}\n",
      "{'loss': 2.9546, 'learning_rate': 5.299047619047619e-06, 'epoch': 2.45}\n",
      "{'loss': 2.7183, 'learning_rate': 5.291428571428572e-06, 'epoch': 2.45}\n",
      "{'loss': 2.5327, 'learning_rate': 5.283809523809525e-06, 'epoch': 2.45}\n",
      "{'loss': 2.391, 'learning_rate': 5.276190476190477e-06, 'epoch': 2.46}\n",
      "{'loss': 1.7659, 'learning_rate': 5.268571428571429e-06, 'epoch': 2.46}\n",
      "{'loss': 2.2612, 'learning_rate': 5.260952380952381e-06, 'epoch': 2.46}\n",
      "{'loss': 2.5997, 'learning_rate': 5.2533333333333336e-06, 'epoch': 2.47}\n",
      "{'loss': 2.5656, 'learning_rate': 5.2457142857142864e-06, 'epoch': 2.47}\n",
      "{'loss': 2.2497, 'learning_rate': 5.2380952380952384e-06, 'epoch': 2.47}\n",
      "{'loss': 1.5132, 'learning_rate': 5.230476190476191e-06, 'epoch': 2.48}\n",
      "{'loss': 2.6987, 'learning_rate': 5.2228571428571425e-06, 'epoch': 2.48}\n",
      "{'loss': 2.4032, 'learning_rate': 5.215238095238095e-06, 'epoch': 2.49}\n",
      "{'loss': 2.335, 'learning_rate': 5.207619047619048e-06, 'epoch': 2.49}\n",
      "{'loss': 1.926, 'learning_rate': 5.2e-06, 'epoch': 2.49}\n",
      "{'loss': 1.8411, 'learning_rate': 5.192380952380953e-06, 'epoch': 2.5}\n",
      "{'loss': 2.4207, 'learning_rate': 5.184761904761905e-06, 'epoch': 2.5}\n",
      "{'loss': 2.2782, 'learning_rate': 5.177142857142857e-06, 'epoch': 2.5}\n",
      "{'loss': 2.2267, 'learning_rate': 5.16952380952381e-06, 'epoch': 2.51}\n",
      "{'loss': 2.5052, 'learning_rate': 5.161904761904763e-06, 'epoch': 2.51}\n",
      "{'loss': 2.5116, 'learning_rate': 5.154285714285715e-06, 'epoch': 2.52}\n",
      "{'loss': 2.1166, 'learning_rate': 5.146666666666668e-06, 'epoch': 2.52}\n",
      "{'loss': 2.3504, 'learning_rate': 5.139047619047619e-06, 'epoch': 2.52}\n",
      "{'loss': 2.1912, 'learning_rate': 5.131428571428572e-06, 'epoch': 2.53}\n",
      "{'loss': 2.1837, 'learning_rate': 5.1238095238095245e-06, 'epoch': 2.53}\n",
      "{'loss': 2.0094, 'learning_rate': 5.1161904761904765e-06, 'epoch': 2.53}\n",
      "{'loss': 1.9034, 'learning_rate': 5.108571428571429e-06, 'epoch': 2.54}\n",
      "{'loss': 2.2827, 'learning_rate': 5.1009523809523806e-06, 'epoch': 2.54}\n",
      "{'loss': 2.5638, 'learning_rate': 5.093333333333333e-06, 'epoch': 2.54}\n",
      "{'loss': 2.3482, 'learning_rate': 5.085714285714286e-06, 'epoch': 2.55}\n",
      "{'loss': 2.2708, 'learning_rate': 5.078095238095238e-06, 'epoch': 2.55}\n",
      "{'loss': 2.3822, 'learning_rate': 5.070476190476191e-06, 'epoch': 2.56}\n",
      "{'loss': 1.9572, 'learning_rate': 5.062857142857144e-06, 'epoch': 2.56}\n",
      "{'loss': 1.8581, 'learning_rate': 5.055238095238095e-06, 'epoch': 2.56}\n",
      "{'loss': 1.491, 'learning_rate': 5.047619047619048e-06, 'epoch': 2.57}\n",
      "{'loss': 2.1724, 'learning_rate': 5.04e-06, 'epoch': 2.57}\n",
      "{'loss': 2.2978, 'learning_rate': 5.032380952380953e-06, 'epoch': 2.57}\n",
      "{'loss': 2.4963, 'learning_rate': 5.024761904761906e-06, 'epoch': 2.58}\n",
      "{'loss': 2.5319, 'learning_rate': 5.017142857142857e-06, 'epoch': 2.58}\n",
      "{'loss': 2.4588, 'learning_rate': 5.00952380952381e-06, 'epoch': 2.58}\n",
      "{'loss': 1.7974, 'learning_rate': 5.001904761904763e-06, 'epoch': 2.59}\n",
      "{'loss': 2.1103, 'learning_rate': 4.994285714285715e-06, 'epoch': 2.59}\n",
      "{'loss': 1.9864, 'learning_rate': 4.986666666666667e-06, 'epoch': 2.6}\n",
      "{'loss': 2.2028, 'learning_rate': 4.9790476190476195e-06, 'epoch': 2.6}\n",
      "{'loss': 2.0009, 'learning_rate': 4.971428571428572e-06, 'epoch': 2.6}\n",
      "{'loss': 3.1176, 'learning_rate': 4.963809523809524e-06, 'epoch': 2.61}\n",
      "{'loss': 2.2012, 'learning_rate': 4.956190476190476e-06, 'epoch': 2.61}\n",
      "{'loss': 1.8541, 'learning_rate': 4.948571428571429e-06, 'epoch': 2.61}\n",
      "{'loss': 2.6708, 'learning_rate': 4.940952380952381e-06, 'epoch': 2.62}\n",
      "{'loss': 2.4703, 'learning_rate': 4.933333333333334e-06, 'epoch': 2.62}\n",
      "{'loss': 2.4174, 'learning_rate': 4.925714285714286e-06, 'epoch': 2.63}\n",
      "{'loss': 2.5044, 'learning_rate': 4.918095238095238e-06, 'epoch': 2.63}\n",
      "{'loss': 2.1227, 'learning_rate': 4.910476190476191e-06, 'epoch': 2.63}\n",
      "{'loss': 2.7273, 'learning_rate': 4.902857142857143e-06, 'epoch': 2.64}\n",
      "{'loss': 1.8677, 'learning_rate': 4.895238095238096e-06, 'epoch': 2.64}\n",
      "{'loss': 2.2127, 'learning_rate': 4.887619047619048e-06, 'epoch': 2.64}\n",
      "{'loss': 2.5354, 'learning_rate': 4.880000000000001e-06, 'epoch': 2.65}\n",
      "{'loss': 2.3038, 'learning_rate': 4.872380952380953e-06, 'epoch': 2.65}\n",
      "{'loss': 2.0371, 'learning_rate': 4.864761904761905e-06, 'epoch': 2.65}\n",
      "{'loss': 2.601, 'learning_rate': 4.857142857142858e-06, 'epoch': 2.66}\n",
      "{'loss': 2.5857, 'learning_rate': 4.8495238095238104e-06, 'epoch': 2.66}\n",
      "{'loss': 1.7458, 'learning_rate': 4.8419047619047625e-06, 'epoch': 2.67}\n",
      "{'loss': 2.0932, 'learning_rate': 4.8342857142857145e-06, 'epoch': 2.67}\n",
      "{'loss': 2.3474, 'learning_rate': 4.826666666666667e-06, 'epoch': 2.67}\n",
      "{'loss': 2.1631, 'learning_rate': 4.819047619047619e-06, 'epoch': 2.68}\n",
      "{'loss': 2.0271, 'learning_rate': 4.811428571428572e-06, 'epoch': 2.68}\n",
      "{'loss': 2.1232, 'learning_rate': 4.803809523809524e-06, 'epoch': 2.68}\n",
      "{'loss': 2.6082, 'learning_rate': 4.796190476190476e-06, 'epoch': 2.69}\n",
      "{'loss': 2.4756, 'learning_rate': 4.788571428571429e-06, 'epoch': 2.69}\n",
      "{'loss': 2.542, 'learning_rate': 4.780952380952381e-06, 'epoch': 2.69}\n",
      "{'loss': 2.3846, 'learning_rate': 4.773333333333334e-06, 'epoch': 2.7}\n",
      "{'loss': 2.1904, 'learning_rate': 4.765714285714286e-06, 'epoch': 2.7}\n",
      "{'loss': 1.872, 'learning_rate': 4.758095238095238e-06, 'epoch': 2.71}\n",
      "{'loss': 2.6167, 'learning_rate': 4.750476190476191e-06, 'epoch': 2.71}\n",
      "{'loss': 2.0009, 'learning_rate': 4.742857142857144e-06, 'epoch': 2.71}\n",
      "{'loss': 2.4446, 'learning_rate': 4.735238095238096e-06, 'epoch': 2.72}\n",
      "{'loss': 2.2084, 'learning_rate': 4.727619047619048e-06, 'epoch': 2.72}\n",
      "{'loss': 2.8035, 'learning_rate': 4.7200000000000005e-06, 'epoch': 2.72}\n",
      "{'loss': 2.3045, 'learning_rate': 4.7123809523809526e-06, 'epoch': 2.73}\n",
      "{'loss': 1.8571, 'learning_rate': 4.704761904761905e-06, 'epoch': 2.73}\n",
      "{'loss': 2.0649, 'learning_rate': 4.6971428571428574e-06, 'epoch': 2.74}\n",
      "{'loss': 1.6561, 'learning_rate': 4.68952380952381e-06, 'epoch': 2.74}\n",
      "{'loss': 2.4029, 'learning_rate': 4.681904761904762e-06, 'epoch': 2.74}\n",
      "{'loss': 2.3486, 'learning_rate': 4.674285714285714e-06, 'epoch': 2.75}\n",
      "{'loss': 2.8719, 'learning_rate': 4.666666666666667e-06, 'epoch': 2.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HOME\\anaconda3\\lib\\site-packages\\peft\\utils\\save_and_load.py:168: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6727, 'learning_rate': 4.659047619047619e-06, 'epoch': 2.75}\n",
      "{'loss': 2.2812, 'learning_rate': 4.651428571428572e-06, 'epoch': 2.76}\n",
      "{'loss': 2.6075, 'learning_rate': 4.643809523809524e-06, 'epoch': 2.76}\n",
      "{'loss': 1.7633, 'learning_rate': 4.636190476190476e-06, 'epoch': 2.76}\n",
      "{'loss': 3.0018, 'learning_rate': 4.628571428571429e-06, 'epoch': 2.77}\n",
      "{'loss': 2.4221, 'learning_rate': 4.620952380952382e-06, 'epoch': 2.77}\n",
      "{'loss': 1.8065, 'learning_rate': 4.613333333333334e-06, 'epoch': 2.78}\n",
      "{'loss': 2.1704, 'learning_rate': 4.605714285714286e-06, 'epoch': 2.78}\n",
      "{'loss': 2.9023, 'learning_rate': 4.598095238095239e-06, 'epoch': 2.78}\n",
      "{'loss': 2.1133, 'learning_rate': 4.590476190476191e-06, 'epoch': 2.79}\n",
      "{'loss': 1.8536, 'learning_rate': 4.5828571428571435e-06, 'epoch': 2.79}\n",
      "{'loss': 2.1823, 'learning_rate': 4.5752380952380955e-06, 'epoch': 2.79}\n",
      "{'loss': 2.0177, 'learning_rate': 4.5676190476190475e-06, 'epoch': 2.8}\n",
      "{'loss': 2.1614, 'learning_rate': 4.56e-06, 'epoch': 2.8}\n",
      "{'loss': 2.3193, 'learning_rate': 4.552380952380952e-06, 'epoch': 2.8}\n",
      "{'loss': 2.14, 'learning_rate': 4.544761904761905e-06, 'epoch': 2.81}\n",
      "{'loss': 2.4453, 'learning_rate': 4.537142857142858e-06, 'epoch': 2.81}\n",
      "{'loss': 1.8807, 'learning_rate': 4.52952380952381e-06, 'epoch': 2.82}\n",
      "{'loss': 2.4454, 'learning_rate': 4.521904761904762e-06, 'epoch': 2.82}\n",
      "{'loss': 2.5445, 'learning_rate': 4.514285714285714e-06, 'epoch': 2.82}\n",
      "{'loss': 2.6141, 'learning_rate': 4.506666666666667e-06, 'epoch': 2.83}\n",
      "{'loss': 2.1426, 'learning_rate': 4.49904761904762e-06, 'epoch': 2.83}\n",
      "{'loss': 2.3838, 'learning_rate': 4.491428571428572e-06, 'epoch': 2.83}\n",
      "{'loss': 2.7377, 'learning_rate': 4.483809523809524e-06, 'epoch': 2.84}\n",
      "{'loss': 1.4996, 'learning_rate': 4.476190476190477e-06, 'epoch': 2.84}\n",
      "{'loss': 2.6513, 'learning_rate': 4.468571428571429e-06, 'epoch': 2.85}\n",
      "{'loss': 1.6162, 'learning_rate': 4.460952380952382e-06, 'epoch': 2.85}\n",
      "{'loss': 2.144, 'learning_rate': 4.453333333333334e-06, 'epoch': 2.85}\n",
      "{'loss': 2.1158, 'learning_rate': 4.445714285714286e-06, 'epoch': 2.86}\n",
      "{'loss': 1.7569, 'learning_rate': 4.4380952380952385e-06, 'epoch': 2.86}\n",
      "{'loss': 2.0756, 'learning_rate': 4.4304761904761905e-06, 'epoch': 2.86}\n",
      "{'loss': 1.9369, 'learning_rate': 4.422857142857143e-06, 'epoch': 2.87}\n",
      "{'loss': 1.834, 'learning_rate': 4.415238095238095e-06, 'epoch': 2.87}\n",
      "{'loss': 1.7405, 'learning_rate': 4.407619047619048e-06, 'epoch': 2.87}\n",
      "{'loss': 1.8067, 'learning_rate': 4.4e-06, 'epoch': 2.88}\n",
      "{'loss': 2.4342, 'learning_rate': 4.392380952380953e-06, 'epoch': 2.88}\n",
      "{'loss': 2.1523, 'learning_rate': 4.384761904761905e-06, 'epoch': 2.89}\n",
      "{'loss': 1.4945, 'learning_rate': 4.377142857142858e-06, 'epoch': 2.89}\n",
      "{'loss': 2.1436, 'learning_rate': 4.36952380952381e-06, 'epoch': 2.89}\n",
      "{'loss': 2.4641, 'learning_rate': 4.361904761904762e-06, 'epoch': 2.9}\n",
      "{'loss': 1.8421, 'learning_rate': 4.354285714285715e-06, 'epoch': 2.9}\n",
      "{'loss': 2.18, 'learning_rate': 4.346666666666667e-06, 'epoch': 2.9}\n",
      "{'loss': 2.2085, 'learning_rate': 4.33904761904762e-06, 'epoch': 2.91}\n",
      "{'loss': 2.2065, 'learning_rate': 4.331428571428572e-06, 'epoch': 2.91}\n",
      "{'loss': 1.6049, 'learning_rate': 4.323809523809524e-06, 'epoch': 2.91}\n",
      "{'loss': 1.8019, 'learning_rate': 4.3161904761904766e-06, 'epoch': 2.92}\n",
      "{'loss': 1.7696, 'learning_rate': 4.3085714285714294e-06, 'epoch': 2.92}\n",
      "{'loss': 1.9612, 'learning_rate': 4.3009523809523814e-06, 'epoch': 2.93}\n",
      "{'loss': 2.437, 'learning_rate': 4.2933333333333334e-06, 'epoch': 2.93}\n",
      "{'loss': 2.1586, 'learning_rate': 4.2857142857142855e-06, 'epoch': 2.93}\n",
      "{'loss': 2.2518, 'learning_rate': 4.278095238095238e-06, 'epoch': 2.94}\n",
      "{'loss': 2.4795, 'learning_rate': 4.270476190476191e-06, 'epoch': 2.94}\n",
      "{'loss': 1.7033, 'learning_rate': 4.262857142857143e-06, 'epoch': 2.94}\n",
      "{'loss': 1.5768, 'learning_rate': 4.255238095238095e-06, 'epoch': 2.95}\n",
      "{'loss': 2.0266, 'learning_rate': 4.247619047619048e-06, 'epoch': 2.95}\n",
      "{'loss': 2.3254, 'learning_rate': 4.24e-06, 'epoch': 2.96}\n",
      "{'loss': 1.9033, 'learning_rate': 4.232380952380953e-06, 'epoch': 2.96}\n",
      "{'loss': 1.5009, 'learning_rate': 4.224761904761905e-06, 'epoch': 2.96}\n",
      "{'loss': 1.9973, 'learning_rate': 4.217142857142858e-06, 'epoch': 2.97}\n",
      "{'loss': 2.0022, 'learning_rate': 4.20952380952381e-06, 'epoch': 2.97}\n",
      "{'loss': 1.9677, 'learning_rate': 4.201904761904762e-06, 'epoch': 2.97}\n",
      "{'loss': 2.0397, 'learning_rate': 4.194285714285715e-06, 'epoch': 2.98}\n",
      "{'loss': 2.0883, 'learning_rate': 4.1866666666666675e-06, 'epoch': 2.98}\n",
      "{'loss': 1.8079, 'learning_rate': 4.1790476190476195e-06, 'epoch': 2.98}\n",
      "{'loss': 1.8331, 'learning_rate': 4.1714285714285715e-06, 'epoch': 2.99}\n",
      "{'loss': 2.2056, 'learning_rate': 4.163809523809524e-06, 'epoch': 2.99}\n",
      "{'loss': 2.8701, 'learning_rate': 4.156190476190476e-06, 'epoch': 3.0}\n",
      "{'loss': 2.2969, 'learning_rate': 4.148571428571429e-06, 'epoch': 3.0}\n",
      "{'loss': 2.2824, 'learning_rate': 4.140952380952381e-06, 'epoch': 3.0}\n",
      "{'loss': 1.8646, 'learning_rate': 4.133333333333333e-06, 'epoch': 3.01}\n",
      "{'loss': 1.8765, 'learning_rate': 4.125714285714286e-06, 'epoch': 3.01}\n",
      "{'loss': 2.2062, 'learning_rate': 4.118095238095238e-06, 'epoch': 3.01}\n",
      "{'loss': 1.7061, 'learning_rate': 4.110476190476191e-06, 'epoch': 3.02}\n",
      "{'loss': 2.0683, 'learning_rate': 4.102857142857143e-06, 'epoch': 3.02}\n",
      "{'loss': 1.8382, 'learning_rate': 4.095238095238096e-06, 'epoch': 3.02}\n",
      "{'loss': 1.6618, 'learning_rate': 4.087619047619048e-06, 'epoch': 3.03}\n",
      "{'loss': 2.0177, 'learning_rate': 4.08e-06, 'epoch': 3.03}\n",
      "{'loss': 2.4419, 'learning_rate': 4.072380952380953e-06, 'epoch': 3.04}\n",
      "{'loss': 1.6576, 'learning_rate': 4.064761904761906e-06, 'epoch': 3.04}\n",
      "{'loss': 2.1364, 'learning_rate': 4.057142857142858e-06, 'epoch': 3.04}\n",
      "{'loss': 2.4489, 'learning_rate': 4.04952380952381e-06, 'epoch': 3.05}\n",
      "{'loss': 2.3628, 'learning_rate': 4.0419047619047625e-06, 'epoch': 3.05}\n",
      "{'loss': 1.8971, 'learning_rate': 4.0342857142857145e-06, 'epoch': 3.05}\n",
      "{'loss': 2.3534, 'learning_rate': 4.026666666666667e-06, 'epoch': 3.06}\n",
      "{'loss': 2.868, 'learning_rate': 4.019047619047619e-06, 'epoch': 3.06}\n",
      "{'loss': 2.7194, 'learning_rate': 4.011428571428571e-06, 'epoch': 3.07}\n",
      "{'loss': 1.5802, 'learning_rate': 4.003809523809524e-06, 'epoch': 3.07}\n",
      "{'loss': 2.2772, 'learning_rate': 3.996190476190476e-06, 'epoch': 3.07}\n",
      "{'loss': 2.3227, 'learning_rate': 3.988571428571429e-06, 'epoch': 3.08}\n",
      "{'loss': 2.1912, 'learning_rate': 3.980952380952381e-06, 'epoch': 3.08}\n",
      "{'loss': 2.7176, 'learning_rate': 3.973333333333333e-06, 'epoch': 3.08}\n",
      "{'loss': 1.7428, 'learning_rate': 3.965714285714286e-06, 'epoch': 3.09}\n",
      "{'loss': 2.0758, 'learning_rate': 3.958095238095239e-06, 'epoch': 3.09}\n",
      "{'loss': 2.0113, 'learning_rate': 3.950476190476191e-06, 'epoch': 3.09}\n",
      "{'loss': 1.7346, 'learning_rate': 3.942857142857143e-06, 'epoch': 3.1}\n",
      "{'loss': 2.2972, 'learning_rate': 3.935238095238096e-06, 'epoch': 3.1}\n",
      "{'loss': 1.891, 'learning_rate': 3.927619047619048e-06, 'epoch': 3.11}\n",
      "{'loss': 1.9157, 'learning_rate': 3.920000000000001e-06, 'epoch': 3.11}\n",
      "{'loss': 2.0375, 'learning_rate': 3.912380952380953e-06, 'epoch': 3.11}\n",
      "{'loss': 2.115, 'learning_rate': 3.9047619047619055e-06, 'epoch': 3.12}\n",
      "{'loss': 2.5551, 'learning_rate': 3.8971428571428575e-06, 'epoch': 3.12}\n",
      "{'loss': 2.1798, 'learning_rate': 3.8895238095238095e-06, 'epoch': 3.12}\n",
      "{'loss': 2.8454, 'learning_rate': 3.881904761904762e-06, 'epoch': 3.13}\n",
      "{'loss': 2.2769, 'learning_rate': 3.874285714285715e-06, 'epoch': 3.13}\n",
      "{'loss': 2.3274, 'learning_rate': 3.866666666666667e-06, 'epoch': 3.13}\n",
      "{'loss': 2.2594, 'learning_rate': 3.859047619047619e-06, 'epoch': 3.14}\n",
      "{'loss': 1.9337, 'learning_rate': 3.851428571428571e-06, 'epoch': 3.14}\n",
      "{'loss': 2.5983, 'learning_rate': 3.843809523809524e-06, 'epoch': 3.15}\n",
      "{'loss': 2.3891, 'learning_rate': 3.836190476190477e-06, 'epoch': 3.15}\n",
      "{'loss': 2.2311, 'learning_rate': 3.828571428571429e-06, 'epoch': 3.15}\n",
      "{'loss': 2.6269, 'learning_rate': 3.820952380952381e-06, 'epoch': 3.16}\n",
      "{'loss': 1.6783, 'learning_rate': 3.813333333333334e-06, 'epoch': 3.16}\n",
      "{'loss': 1.5773, 'learning_rate': 3.805714285714286e-06, 'epoch': 3.16}\n",
      "{'loss': 2.7426, 'learning_rate': 3.7980952380952387e-06, 'epoch': 3.17}\n",
      "{'loss': 1.5391, 'learning_rate': 3.7904761904761907e-06, 'epoch': 3.17}\n",
      "{'loss': 1.9707, 'learning_rate': 3.782857142857143e-06, 'epoch': 3.18}\n",
      "{'loss': 2.0907, 'learning_rate': 3.7752380952380956e-06, 'epoch': 3.18}\n",
      "{'loss': 2.2961, 'learning_rate': 3.7676190476190476e-06, 'epoch': 3.18}\n",
      "{'loss': 2.1943, 'learning_rate': 3.7600000000000004e-06, 'epoch': 3.19}\n",
      "{'loss': 2.0995, 'learning_rate': 3.752380952380953e-06, 'epoch': 3.19}\n",
      "{'loss': 2.1436, 'learning_rate': 3.744761904761905e-06, 'epoch': 3.19}\n",
      "{'loss': 2.1386, 'learning_rate': 3.7371428571428577e-06, 'epoch': 3.2}\n",
      "{'loss': 1.9541, 'learning_rate': 3.72952380952381e-06, 'epoch': 3.2}\n",
      "{'loss': 1.9853, 'learning_rate': 3.721904761904762e-06, 'epoch': 3.2}\n",
      "{'loss': 2.0392, 'learning_rate': 3.7142857142857146e-06, 'epoch': 3.21}\n",
      "{'loss': 2.0256, 'learning_rate': 3.7066666666666666e-06, 'epoch': 3.21}\n",
      "{'loss': 2.4404, 'learning_rate': 3.6990476190476195e-06, 'epoch': 3.22}\n",
      "{'loss': 2.0704, 'learning_rate': 3.691428571428572e-06, 'epoch': 3.22}\n",
      "{'loss': 2.2577, 'learning_rate': 3.683809523809524e-06, 'epoch': 3.22}\n",
      "{'loss': 1.9313, 'learning_rate': 3.6761904761904763e-06, 'epoch': 3.23}\n",
      "{'loss': 2.6107, 'learning_rate': 3.668571428571429e-06, 'epoch': 3.23}\n",
      "{'loss': 2.4334, 'learning_rate': 3.6609523809523812e-06, 'epoch': 3.23}\n",
      "{'loss': 2.1187, 'learning_rate': 3.6533333333333336e-06, 'epoch': 3.24}\n",
      "{'loss': 2.29, 'learning_rate': 3.6457142857142857e-06, 'epoch': 3.24}\n",
      "{'loss': 2.8134, 'learning_rate': 3.6380952380952385e-06, 'epoch': 3.24}\n",
      "{'loss': 2.4194, 'learning_rate': 3.630476190476191e-06, 'epoch': 3.25}\n",
      "{'loss': 2.5981, 'learning_rate': 3.622857142857143e-06, 'epoch': 3.25}\n",
      "{'loss': 2.0555, 'learning_rate': 3.6152380952380954e-06, 'epoch': 3.26}\n",
      "{'loss': 2.1628, 'learning_rate': 3.6076190476190483e-06, 'epoch': 3.26}\n",
      "{'loss': 2.3299, 'learning_rate': 3.6000000000000003e-06, 'epoch': 3.26}\n",
      "{'loss': 1.9323, 'learning_rate': 3.5923809523809527e-06, 'epoch': 3.27}\n",
      "{'loss': 2.0741, 'learning_rate': 3.584761904761905e-06, 'epoch': 3.27}\n",
      "{'loss': 2.3447, 'learning_rate': 3.5771428571428576e-06, 'epoch': 3.27}\n",
      "{'loss': 1.9814, 'learning_rate': 3.56952380952381e-06, 'epoch': 3.28}\n",
      "{'loss': 1.9208, 'learning_rate': 3.561904761904762e-06, 'epoch': 3.28}\n",
      "{'loss': 1.4711, 'learning_rate': 3.5542857142857144e-06, 'epoch': 3.29}\n",
      "{'loss': 1.9625, 'learning_rate': 3.5466666666666673e-06, 'epoch': 3.29}\n",
      "{'loss': 2.3733, 'learning_rate': 3.5390476190476193e-06, 'epoch': 3.29}\n",
      "{'loss': 2.2315, 'learning_rate': 3.5314285714285717e-06, 'epoch': 3.3}\n",
      "{'loss': 1.9139, 'learning_rate': 3.523809523809524e-06, 'epoch': 3.3}\n",
      "{'loss': 2.073, 'learning_rate': 3.516190476190476e-06, 'epoch': 3.3}\n",
      "{'loss': 2.2599, 'learning_rate': 3.508571428571429e-06, 'epoch': 3.31}\n",
      "{'loss': 2.1628, 'learning_rate': 3.500952380952381e-06, 'epoch': 3.31}\n",
      "{'loss': 2.3152, 'learning_rate': 3.4933333333333335e-06, 'epoch': 3.31}\n",
      "{'loss': 1.6601, 'learning_rate': 3.4857142857142863e-06, 'epoch': 3.32}\n",
      "{'loss': 2.3196, 'learning_rate': 3.4780952380952384e-06, 'epoch': 3.32}\n",
      "{'loss': 1.9406, 'learning_rate': 3.4704761904761908e-06, 'epoch': 3.33}\n",
      "{'loss': 1.3935, 'learning_rate': 3.4628571428571432e-06, 'epoch': 3.33}\n",
      "{'loss': 2.1478, 'learning_rate': 3.4552380952380952e-06, 'epoch': 3.33}\n",
      "{'loss': 2.3924, 'learning_rate': 3.447619047619048e-06, 'epoch': 3.34}\n",
      "{'loss': 2.3186, 'learning_rate': 3.44e-06, 'epoch': 3.34}\n",
      "{'loss': 1.7448, 'learning_rate': 3.4323809523809525e-06, 'epoch': 3.34}\n",
      "{'loss': 2.0109, 'learning_rate': 3.424761904761905e-06, 'epoch': 3.35}\n",
      "{'loss': 2.0234, 'learning_rate': 3.4171428571428574e-06, 'epoch': 3.35}\n",
      "{'loss': 2.0981, 'learning_rate': 3.40952380952381e-06, 'epoch': 3.35}\n",
      "{'loss': 2.1499, 'learning_rate': 3.4019047619047623e-06, 'epoch': 3.36}\n",
      "{'loss': 2.2988, 'learning_rate': 3.3942857142857143e-06, 'epoch': 3.36}\n",
      "{'loss': 2.2354, 'learning_rate': 3.386666666666667e-06, 'epoch': 3.37}\n",
      "{'loss': 2.3102, 'learning_rate': 3.3790476190476196e-06, 'epoch': 3.37}\n",
      "{'loss': 2.0745, 'learning_rate': 3.3714285714285716e-06, 'epoch': 3.37}\n",
      "{'loss': 1.6203, 'learning_rate': 3.363809523809524e-06, 'epoch': 3.38}\n",
      "{'loss': 2.3996, 'learning_rate': 3.356190476190476e-06, 'epoch': 3.38}\n",
      "{'loss': 2.1188, 'learning_rate': 3.348571428571429e-06, 'epoch': 3.38}\n",
      "{'loss': 2.0854, 'learning_rate': 3.3409523809523813e-06, 'epoch': 3.39}\n",
      "{'loss': 1.954, 'learning_rate': 3.3333333333333333e-06, 'epoch': 3.39}\n",
      "{'loss': 2.1737, 'learning_rate': 3.325714285714286e-06, 'epoch': 3.4}\n",
      "{'loss': 2.2375, 'learning_rate': 3.3180952380952386e-06, 'epoch': 3.4}\n",
      "{'loss': 2.1591, 'learning_rate': 3.3104761904761906e-06, 'epoch': 3.4}\n",
      "{'loss': 1.7114, 'learning_rate': 3.302857142857143e-06, 'epoch': 3.41}\n",
      "{'loss': 1.9158, 'learning_rate': 3.295238095238095e-06, 'epoch': 3.41}\n",
      "{'loss': 1.5388, 'learning_rate': 3.287619047619048e-06, 'epoch': 3.41}\n",
      "{'loss': 2.0646, 'learning_rate': 3.2800000000000004e-06, 'epoch': 3.42}\n",
      "{'loss': 1.6351, 'learning_rate': 3.2723809523809524e-06, 'epoch': 3.42}\n",
      "{'loss': 2.3142, 'learning_rate': 3.2647619047619052e-06, 'epoch': 3.42}\n",
      "{'loss': 2.1682, 'learning_rate': 3.2571428571428577e-06, 'epoch': 3.43}\n",
      "{'loss': 2.2727, 'learning_rate': 3.2495238095238097e-06, 'epoch': 3.43}\n",
      "{'loss': 1.7717, 'learning_rate': 3.241904761904762e-06, 'epoch': 3.44}\n",
      "{'loss': 2.5522, 'learning_rate': 3.234285714285715e-06, 'epoch': 3.44}\n",
      "{'loss': 2.5167, 'learning_rate': 3.226666666666667e-06, 'epoch': 3.44}\n",
      "{'loss': 2.2294, 'learning_rate': 3.2190476190476194e-06, 'epoch': 3.45}\n",
      "{'loss': 2.1039, 'learning_rate': 3.2114285714285714e-06, 'epoch': 3.45}\n",
      "{'loss': 2.5047, 'learning_rate': 3.203809523809524e-06, 'epoch': 3.45}\n",
      "{'loss': 2.0884, 'learning_rate': 3.1961904761904767e-06, 'epoch': 3.46}\n",
      "{'loss': 2.2228, 'learning_rate': 3.1885714285714287e-06, 'epoch': 3.46}\n",
      "{'loss': 2.4074, 'learning_rate': 3.180952380952381e-06, 'epoch': 3.46}\n",
      "{'loss': 1.9729, 'learning_rate': 3.173333333333334e-06, 'epoch': 3.47}\n",
      "{'loss': 1.9566, 'learning_rate': 3.165714285714286e-06, 'epoch': 3.47}\n",
      "{'loss': 1.5597, 'learning_rate': 3.1580952380952385e-06, 'epoch': 3.48}\n",
      "{'loss': 2.9049, 'learning_rate': 3.1504761904761905e-06, 'epoch': 3.48}\n",
      "{'loss': 2.0996, 'learning_rate': 3.142857142857143e-06, 'epoch': 3.48}\n",
      "{'loss': 3.0228, 'learning_rate': 3.1352380952380958e-06, 'epoch': 3.49}\n",
      "{'loss': 2.5607, 'learning_rate': 3.1276190476190478e-06, 'epoch': 3.49}\n",
      "{'loss': 2.027, 'learning_rate': 3.12e-06, 'epoch': 3.49}\n",
      "{'loss': 1.8288, 'learning_rate': 3.1123809523809526e-06, 'epoch': 3.5}\n",
      "{'loss': 2.0243, 'learning_rate': 3.104761904761905e-06, 'epoch': 3.5}\n",
      "{'loss': 1.7656, 'learning_rate': 3.0971428571428575e-06, 'epoch': 3.51}\n",
      "{'loss': 2.3321, 'learning_rate': 3.08952380952381e-06, 'epoch': 3.51}\n",
      "{'loss': 2.6083, 'learning_rate': 3.081904761904762e-06, 'epoch': 3.51}\n",
      "{'loss': 1.8909, 'learning_rate': 3.074285714285715e-06, 'epoch': 3.52}\n",
      "{'loss': 1.4203, 'learning_rate': 3.066666666666667e-06, 'epoch': 3.52}\n",
      "{'loss': 1.7792, 'learning_rate': 3.0590476190476192e-06, 'epoch': 3.52}\n",
      "{'loss': 2.0861, 'learning_rate': 3.0514285714285717e-06, 'epoch': 3.53}\n",
      "{'loss': 2.3514, 'learning_rate': 3.0438095238095237e-06, 'epoch': 3.53}\n",
      "{'loss': 1.7431, 'learning_rate': 3.0361904761904765e-06, 'epoch': 3.53}\n",
      "{'loss': 2.2021, 'learning_rate': 3.028571428571429e-06, 'epoch': 3.54}\n",
      "{'loss': 2.1228, 'learning_rate': 3.020952380952381e-06, 'epoch': 3.54}\n",
      "{'loss': 1.9869, 'learning_rate': 3.013333333333334e-06, 'epoch': 3.55}\n",
      "{'loss': 2.2018, 'learning_rate': 3.005714285714286e-06, 'epoch': 3.55}\n",
      "{'loss': 1.7984, 'learning_rate': 2.9980952380952383e-06, 'epoch': 3.55}\n",
      "{'loss': 2.1889, 'learning_rate': 2.9904761904761907e-06, 'epoch': 3.56}\n",
      "{'loss': 1.6572, 'learning_rate': 2.9828571428571427e-06, 'epoch': 3.56}\n",
      "{'loss': 2.2291, 'learning_rate': 2.9752380952380956e-06, 'epoch': 3.56}\n",
      "{'loss': 2.0184, 'learning_rate': 2.967619047619048e-06, 'epoch': 3.57}\n",
      "{'loss': 2.0826, 'learning_rate': 2.96e-06, 'epoch': 3.57}\n",
      "{'loss': 1.8369, 'learning_rate': 2.9523809523809525e-06, 'epoch': 3.57}\n",
      "{'loss': 1.732, 'learning_rate': 2.9447619047619053e-06, 'epoch': 3.58}\n",
      "{'loss': 2.4421, 'learning_rate': 2.9371428571428573e-06, 'epoch': 3.58}\n",
      "{'loss': 2.0945, 'learning_rate': 2.9295238095238098e-06, 'epoch': 3.59}\n",
      "{'loss': 1.9792, 'learning_rate': 2.9219047619047618e-06, 'epoch': 3.59}\n",
      "{'loss': 2.0501, 'learning_rate': 2.9142857142857146e-06, 'epoch': 3.59}\n",
      "{'loss': 2.1212, 'learning_rate': 2.906666666666667e-06, 'epoch': 3.6}\n",
      "{'loss': 2.3657, 'learning_rate': 2.899047619047619e-06, 'epoch': 3.6}\n",
      "{'loss': 2.0455, 'learning_rate': 2.8914285714285715e-06, 'epoch': 3.6}\n",
      "{'loss': 2.6555, 'learning_rate': 2.8838095238095244e-06, 'epoch': 3.61}\n",
      "{'loss': 2.9786, 'learning_rate': 2.8761904761904764e-06, 'epoch': 3.61}\n",
      "{'loss': 2.0661, 'learning_rate': 2.868571428571429e-06, 'epoch': 3.62}\n",
      "{'loss': 2.3142, 'learning_rate': 2.860952380952381e-06, 'epoch': 3.62}\n",
      "{'loss': 2.4438, 'learning_rate': 2.8533333333333337e-06, 'epoch': 3.62}\n",
      "{'loss': 2.2629, 'learning_rate': 2.845714285714286e-06, 'epoch': 3.63}\n",
      "{'loss': 2.0786, 'learning_rate': 2.838095238095238e-06, 'epoch': 3.63}\n",
      "{'loss': 1.4786, 'learning_rate': 2.8304761904761906e-06, 'epoch': 3.63}\n",
      "{'loss': 1.9639, 'learning_rate': 2.8228571428571434e-06, 'epoch': 3.64}\n",
      "{'loss': 2.4489, 'learning_rate': 2.8152380952380954e-06, 'epoch': 3.64}\n",
      "{'loss': 2.7199, 'learning_rate': 2.807619047619048e-06, 'epoch': 3.64}\n",
      "{'loss': 1.7725, 'learning_rate': 2.8000000000000003e-06, 'epoch': 3.65}\n",
      "{'loss': 2.2923, 'learning_rate': 2.7923809523809527e-06, 'epoch': 3.65}\n",
      "{'loss': 2.2796, 'learning_rate': 2.784761904761905e-06, 'epoch': 3.66}\n",
      "{'loss': 2.0439, 'learning_rate': 2.777142857142857e-06, 'epoch': 3.66}\n",
      "{'loss': 2.0735, 'learning_rate': 2.7695238095238096e-06, 'epoch': 3.66}\n",
      "{'loss': 2.0765, 'learning_rate': 2.7619047619047625e-06, 'epoch': 3.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HOME\\anaconda3\\lib\\site-packages\\peft\\utils\\save_and_load.py:168: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0897, 'learning_rate': 2.7542857142857145e-06, 'epoch': 3.67}\n",
      "{'loss': 1.8044, 'learning_rate': 2.746666666666667e-06, 'epoch': 3.67}\n",
      "{'loss': 1.9842, 'learning_rate': 2.7390476190476193e-06, 'epoch': 3.68}\n",
      "{'loss': 2.3677, 'learning_rate': 2.7314285714285714e-06, 'epoch': 3.68}\n",
      "{'loss': 1.8572, 'learning_rate': 2.723809523809524e-06, 'epoch': 3.68}\n",
      "{'loss': 2.1046, 'learning_rate': 2.7161904761904762e-06, 'epoch': 3.69}\n",
      "{'loss': 2.5128, 'learning_rate': 2.7085714285714287e-06, 'epoch': 3.69}\n",
      "{'loss': 2.2816, 'learning_rate': 2.7009523809523815e-06, 'epoch': 3.7}\n",
      "{'loss': 1.9353, 'learning_rate': 2.6933333333333335e-06, 'epoch': 3.7}\n",
      "{'loss': 2.2687, 'learning_rate': 2.685714285714286e-06, 'epoch': 3.7}\n",
      "{'loss': 2.1108, 'learning_rate': 2.6780952380952384e-06, 'epoch': 3.71}\n",
      "{'loss': 1.7277, 'learning_rate': 2.6704761904761904e-06, 'epoch': 3.71}\n",
      "{'loss': 1.9568, 'learning_rate': 2.6628571428571433e-06, 'epoch': 3.71}\n",
      "{'loss': 1.7718, 'learning_rate': 2.6552380952380957e-06, 'epoch': 3.72}\n",
      "{'loss': 2.0889, 'learning_rate': 2.6476190476190477e-06, 'epoch': 3.72}\n",
      "{'loss': 1.9914, 'learning_rate': 2.64e-06, 'epoch': 3.73}\n",
      "{'loss': 1.7346, 'learning_rate': 2.6323809523809526e-06, 'epoch': 3.73}\n",
      "{'loss': 1.9171, 'learning_rate': 2.624761904761905e-06, 'epoch': 3.73}\n",
      "{'loss': 1.6799, 'learning_rate': 2.6171428571428574e-06, 'epoch': 3.74}\n",
      "{'loss': 2.7158, 'learning_rate': 2.6095238095238094e-06, 'epoch': 3.74}\n",
      "{'loss': 2.1267, 'learning_rate': 2.6019047619047623e-06, 'epoch': 3.74}\n",
      "{'loss': 1.7596, 'learning_rate': 2.5942857142857147e-06, 'epoch': 3.75}\n",
      "{'loss': 1.6508, 'learning_rate': 2.5866666666666667e-06, 'epoch': 3.75}\n",
      "{'loss': 2.1067, 'learning_rate': 2.579047619047619e-06, 'epoch': 3.75}\n",
      "{'loss': 1.4841, 'learning_rate': 2.571428571428571e-06, 'epoch': 3.76}\n",
      "{'loss': 1.9848, 'learning_rate': 2.563809523809524e-06, 'epoch': 3.76}\n",
      "{'loss': 1.6793, 'learning_rate': 2.5561904761904765e-06, 'epoch': 3.77}\n",
      "{'loss': 2.133, 'learning_rate': 2.5485714285714285e-06, 'epoch': 3.77}\n",
      "{'loss': 2.0964, 'learning_rate': 2.5409523809523813e-06, 'epoch': 3.77}\n",
      "{'loss': 1.9284, 'learning_rate': 2.5333333333333338e-06, 'epoch': 3.78}\n",
      "{'loss': 2.01, 'learning_rate': 2.525714285714286e-06, 'epoch': 3.78}\n",
      "{'loss': 1.9156, 'learning_rate': 2.5180952380952382e-06, 'epoch': 3.78}\n",
      "{'loss': 1.7599, 'learning_rate': 2.510476190476191e-06, 'epoch': 3.79}\n",
      "{'loss': 1.8179, 'learning_rate': 2.502857142857143e-06, 'epoch': 3.79}\n",
      "{'loss': 2.0929, 'learning_rate': 2.4952380952380955e-06, 'epoch': 3.79}\n",
      "{'loss': 2.0235, 'learning_rate': 2.487619047619048e-06, 'epoch': 3.8}\n",
      "{'loss': 1.9896, 'learning_rate': 2.4800000000000004e-06, 'epoch': 3.8}\n",
      "{'loss': 2.2251, 'learning_rate': 2.4723809523809524e-06, 'epoch': 3.81}\n",
      "{'loss': 1.7803, 'learning_rate': 2.4647619047619053e-06, 'epoch': 3.81}\n",
      "{'loss': 2.183, 'learning_rate': 2.4571428571428573e-06, 'epoch': 3.81}\n",
      "{'loss': 1.7753, 'learning_rate': 2.4495238095238097e-06, 'epoch': 3.82}\n",
      "{'loss': 1.9454, 'learning_rate': 2.441904761904762e-06, 'epoch': 3.82}\n",
      "{'loss': 2.1215, 'learning_rate': 2.4342857142857146e-06, 'epoch': 3.82}\n",
      "{'loss': 2.37, 'learning_rate': 2.426666666666667e-06, 'epoch': 3.83}\n",
      "{'loss': 2.1126, 'learning_rate': 2.419047619047619e-06, 'epoch': 3.83}\n",
      "{'loss': 2.044, 'learning_rate': 2.4114285714285715e-06, 'epoch': 3.84}\n",
      "{'loss': 1.9115, 'learning_rate': 2.403809523809524e-06, 'epoch': 3.84}\n",
      "{'loss': 2.1251, 'learning_rate': 2.3961904761904763e-06, 'epoch': 3.84}\n",
      "{'loss': 1.7982, 'learning_rate': 2.3885714285714288e-06, 'epoch': 3.85}\n",
      "{'loss': 2.2657, 'learning_rate': 2.380952380952381e-06, 'epoch': 3.85}\n",
      "{'loss': 1.4858, 'learning_rate': 2.3733333333333336e-06, 'epoch': 3.85}\n",
      "{'loss': 2.5703, 'learning_rate': 2.365714285714286e-06, 'epoch': 3.86}\n",
      "{'loss': 2.0301, 'learning_rate': 2.358095238095238e-06, 'epoch': 3.86}\n",
      "{'loss': 2.2951, 'learning_rate': 2.350476190476191e-06, 'epoch': 3.86}\n",
      "{'loss': 1.8151, 'learning_rate': 2.342857142857143e-06, 'epoch': 3.87}\n",
      "{'loss': 2.1788, 'learning_rate': 2.3352380952380954e-06, 'epoch': 3.87}\n",
      "{'loss': 1.873, 'learning_rate': 2.327619047619048e-06, 'epoch': 3.88}\n",
      "{'loss': 1.9352, 'learning_rate': 2.3200000000000002e-06, 'epoch': 3.88}\n",
      "{'loss': 1.909, 'learning_rate': 2.3123809523809527e-06, 'epoch': 3.88}\n",
      "{'loss': 2.0251, 'learning_rate': 2.304761904761905e-06, 'epoch': 3.89}\n",
      "{'loss': 2.0699, 'learning_rate': 2.297142857142857e-06, 'epoch': 3.89}\n",
      "{'loss': 2.385, 'learning_rate': 2.28952380952381e-06, 'epoch': 3.89}\n",
      "{'loss': 2.0394, 'learning_rate': 2.281904761904762e-06, 'epoch': 3.9}\n",
      "{'loss': 2.3064, 'learning_rate': 2.2742857142857144e-06, 'epoch': 3.9}\n",
      "{'loss': 2.2024, 'learning_rate': 2.266666666666667e-06, 'epoch': 3.9}\n",
      "{'loss': 2.0027, 'learning_rate': 2.2590476190476193e-06, 'epoch': 3.91}\n",
      "{'loss': 2.1301, 'learning_rate': 2.2514285714285717e-06, 'epoch': 3.91}\n",
      "{'loss': 2.3588, 'learning_rate': 2.243809523809524e-06, 'epoch': 3.92}\n",
      "{'loss': 2.7147, 'learning_rate': 2.236190476190476e-06, 'epoch': 3.92}\n",
      "{'loss': 1.922, 'learning_rate': 2.228571428571429e-06, 'epoch': 3.92}\n",
      "{'loss': 1.7545, 'learning_rate': 2.220952380952381e-06, 'epoch': 3.93}\n",
      "{'loss': 1.1272, 'learning_rate': 2.2133333333333335e-06, 'epoch': 3.93}\n",
      "{'loss': 2.1228, 'learning_rate': 2.205714285714286e-06, 'epoch': 3.93}\n",
      "{'loss': 2.314, 'learning_rate': 2.1980952380952383e-06, 'epoch': 3.94}\n",
      "{'loss': 1.9991, 'learning_rate': 2.1904761904761908e-06, 'epoch': 3.94}\n",
      "{'loss': 2.2927, 'learning_rate': 2.1828571428571428e-06, 'epoch': 3.95}\n",
      "{'loss': 1.7535, 'learning_rate': 2.1752380952380956e-06, 'epoch': 3.95}\n",
      "{'loss': 2.2676, 'learning_rate': 2.1676190476190476e-06, 'epoch': 3.95}\n",
      "{'loss': 2.2694, 'learning_rate': 2.16e-06, 'epoch': 3.96}\n",
      "{'loss': 2.2036, 'learning_rate': 2.1523809523809525e-06, 'epoch': 3.96}\n",
      "{'loss': 1.5698, 'learning_rate': 2.144761904761905e-06, 'epoch': 3.96}\n",
      "{'loss': 1.7514, 'learning_rate': 2.1371428571428574e-06, 'epoch': 3.97}\n",
      "{'loss': 2.5805, 'learning_rate': 2.12952380952381e-06, 'epoch': 3.97}\n",
      "{'loss': 1.3336, 'learning_rate': 2.121904761904762e-06, 'epoch': 3.97}\n",
      "{'loss': 2.7452, 'learning_rate': 2.1142857142857147e-06, 'epoch': 3.98}\n",
      "{'loss': 1.8981, 'learning_rate': 2.1066666666666667e-06, 'epoch': 3.98}\n",
      "{'loss': 1.9951, 'learning_rate': 2.099047619047619e-06, 'epoch': 3.99}\n",
      "{'loss': 1.989, 'learning_rate': 2.0914285714285716e-06, 'epoch': 3.99}\n",
      "{'loss': 1.7118, 'learning_rate': 2.083809523809524e-06, 'epoch': 3.99}\n",
      "{'loss': 1.9842, 'learning_rate': 2.0761904761904764e-06, 'epoch': 4.0}\n",
      "{'loss': 2.3922, 'learning_rate': 2.068571428571429e-06, 'epoch': 4.0}\n",
      "{'loss': 2.1318, 'learning_rate': 2.0609523809523813e-06, 'epoch': 4.0}\n",
      "{'loss': 1.6893, 'learning_rate': 2.0533333333333337e-06, 'epoch': 4.01}\n",
      "{'loss': 1.8346, 'learning_rate': 2.0457142857142857e-06, 'epoch': 4.01}\n",
      "{'loss': 1.7719, 'learning_rate': 2.038095238095238e-06, 'epoch': 4.01}\n",
      "{'loss': 1.7626, 'learning_rate': 2.0304761904761906e-06, 'epoch': 4.02}\n",
      "{'loss': 1.7636, 'learning_rate': 2.022857142857143e-06, 'epoch': 4.02}\n",
      "{'loss': 1.9138, 'learning_rate': 2.0152380952380955e-06, 'epoch': 4.03}\n",
      "{'loss': 2.3237, 'learning_rate': 2.007619047619048e-06, 'epoch': 4.03}\n",
      "{'loss': 1.6285, 'learning_rate': 2.0000000000000003e-06, 'epoch': 4.03}\n",
      "{'loss': 1.8873, 'learning_rate': 1.9923809523809528e-06, 'epoch': 4.04}\n",
      "{'loss': 1.7431, 'learning_rate': 1.9847619047619048e-06, 'epoch': 4.04}\n",
      "{'loss': 2.57, 'learning_rate': 1.977142857142857e-06, 'epoch': 4.04}\n",
      "{'loss': 2.1503, 'learning_rate': 1.9695238095238096e-06, 'epoch': 4.05}\n",
      "{'loss': 2.0571, 'learning_rate': 1.961904761904762e-06, 'epoch': 4.05}\n",
      "{'loss': 2.3783, 'learning_rate': 1.9542857142857145e-06, 'epoch': 4.05}\n",
      "{'loss': 2.1942, 'learning_rate': 1.9466666666666665e-06, 'epoch': 4.06}\n",
      "{'loss': 2.0186, 'learning_rate': 1.9390476190476194e-06, 'epoch': 4.06}\n",
      "{'loss': 2.0742, 'learning_rate': 1.9314285714285714e-06, 'epoch': 4.07}\n",
      "{'loss': 1.9265, 'learning_rate': 1.923809523809524e-06, 'epoch': 4.07}\n",
      "{'loss': 1.6037, 'learning_rate': 1.9161904761904763e-06, 'epoch': 4.07}\n",
      "{'loss': 1.729, 'learning_rate': 1.9085714285714287e-06, 'epoch': 4.08}\n",
      "{'loss': 2.3498, 'learning_rate': 1.9009523809523811e-06, 'epoch': 4.08}\n",
      "{'loss': 1.4559, 'learning_rate': 1.8933333333333333e-06, 'epoch': 4.08}\n",
      "{'loss': 2.1169, 'learning_rate': 1.885714285714286e-06, 'epoch': 4.09}\n",
      "{'loss': 2.0581, 'learning_rate': 1.8780952380952382e-06, 'epoch': 4.09}\n",
      "{'loss': 1.9037, 'learning_rate': 1.8704761904761906e-06, 'epoch': 4.1}\n",
      "{'loss': 2.0726, 'learning_rate': 1.8628571428571429e-06, 'epoch': 4.1}\n",
      "{'loss': 1.7124, 'learning_rate': 1.8552380952380955e-06, 'epoch': 4.1}\n",
      "{'loss': 1.8377, 'learning_rate': 1.8476190476190477e-06, 'epoch': 4.11}\n",
      "{'loss': 1.7605, 'learning_rate': 1.8400000000000002e-06, 'epoch': 4.11}\n",
      "{'loss': 1.5052, 'learning_rate': 1.8323809523809524e-06, 'epoch': 4.11}\n",
      "{'loss': 1.969, 'learning_rate': 1.824761904761905e-06, 'epoch': 4.12}\n",
      "{'loss': 2.159, 'learning_rate': 1.8171428571428573e-06, 'epoch': 4.12}\n",
      "{'loss': 2.1783, 'learning_rate': 1.8095238095238097e-06, 'epoch': 4.12}\n",
      "{'loss': 2.324, 'learning_rate': 1.801904761904762e-06, 'epoch': 4.13}\n",
      "{'loss': 1.9651, 'learning_rate': 1.7942857142857146e-06, 'epoch': 4.13}\n",
      "{'loss': 2.3789, 'learning_rate': 1.7866666666666668e-06, 'epoch': 4.14}\n",
      "{'loss': 2.533, 'learning_rate': 1.7790476190476192e-06, 'epoch': 4.14}\n",
      "{'loss': 2.1208, 'learning_rate': 1.7714285714285714e-06, 'epoch': 4.14}\n",
      "{'loss': 2.1593, 'learning_rate': 1.763809523809524e-06, 'epoch': 4.15}\n",
      "{'loss': 2.1702, 'learning_rate': 1.7561904761904763e-06, 'epoch': 4.15}\n",
      "{'loss': 2.3936, 'learning_rate': 1.7485714285714287e-06, 'epoch': 4.15}\n",
      "{'loss': 1.9011, 'learning_rate': 1.7409523809523812e-06, 'epoch': 4.16}\n",
      "{'loss': 2.0592, 'learning_rate': 1.7333333333333336e-06, 'epoch': 4.16}\n",
      "{'loss': 2.3551, 'learning_rate': 1.7257142857142858e-06, 'epoch': 4.16}\n",
      "{'loss': 2.0098, 'learning_rate': 1.718095238095238e-06, 'epoch': 4.17}\n",
      "{'loss': 2.1282, 'learning_rate': 1.7104761904761907e-06, 'epoch': 4.17}\n",
      "{'loss': 2.4407, 'learning_rate': 1.7028571428571431e-06, 'epoch': 4.18}\n",
      "{'loss': 2.0036, 'learning_rate': 1.6952380952380954e-06, 'epoch': 4.18}\n",
      "{'loss': 2.0345, 'learning_rate': 1.6876190476190476e-06, 'epoch': 4.18}\n",
      "{'loss': 2.6818, 'learning_rate': 1.6800000000000002e-06, 'epoch': 4.19}\n",
      "{'loss': 2.0574, 'learning_rate': 1.6723809523809527e-06, 'epoch': 4.19}\n",
      "{'loss': 2.1241, 'learning_rate': 1.6647619047619049e-06, 'epoch': 4.19}\n",
      "{'loss': 1.8798, 'learning_rate': 1.657142857142857e-06, 'epoch': 4.2}\n",
      "{'loss': 1.6809, 'learning_rate': 1.6495238095238097e-06, 'epoch': 4.2}\n",
      "{'loss': 1.7665, 'learning_rate': 1.641904761904762e-06, 'epoch': 4.21}\n",
      "{'loss': 2.3606, 'learning_rate': 1.6342857142857144e-06, 'epoch': 4.21}\n",
      "{'loss': 1.8892, 'learning_rate': 1.6266666666666666e-06, 'epoch': 4.21}\n",
      "{'loss': 1.909, 'learning_rate': 1.6190476190476193e-06, 'epoch': 4.22}\n",
      "{'loss': 2.2026, 'learning_rate': 1.6114285714285715e-06, 'epoch': 4.22}\n",
      "{'loss': 2.0909, 'learning_rate': 1.603809523809524e-06, 'epoch': 4.22}\n",
      "{'loss': 2.2743, 'learning_rate': 1.5961904761904764e-06, 'epoch': 4.23}\n",
      "{'loss': 2.5065, 'learning_rate': 1.5885714285714288e-06, 'epoch': 4.23}\n",
      "{'loss': 2.2733, 'learning_rate': 1.580952380952381e-06, 'epoch': 4.23}\n",
      "{'loss': 2.2149, 'learning_rate': 1.5733333333333334e-06, 'epoch': 4.24}\n",
      "{'loss': 1.6851, 'learning_rate': 1.5657142857142859e-06, 'epoch': 4.24}\n",
      "{'loss': 1.9445, 'learning_rate': 1.5580952380952383e-06, 'epoch': 4.25}\n",
      "{'loss': 2.1968, 'learning_rate': 1.5504761904761905e-06, 'epoch': 4.25}\n",
      "{'loss': 1.8103, 'learning_rate': 1.542857142857143e-06, 'epoch': 4.25}\n",
      "{'loss': 2.2196, 'learning_rate': 1.5352380952380954e-06, 'epoch': 4.26}\n",
      "{'loss': 2.116, 'learning_rate': 1.5276190476190478e-06, 'epoch': 4.26}\n",
      "{'loss': 1.7979, 'learning_rate': 1.52e-06, 'epoch': 4.26}\n",
      "{'loss': 2.3361, 'learning_rate': 1.5123809523809525e-06, 'epoch': 4.27}\n",
      "{'loss': 2.2925, 'learning_rate': 1.504761904761905e-06, 'epoch': 4.27}\n",
      "{'loss': 2.1946, 'learning_rate': 1.4971428571428574e-06, 'epoch': 4.27}\n",
      "{'loss': 2.191, 'learning_rate': 1.4895238095238096e-06, 'epoch': 4.28}\n",
      "{'loss': 1.7692, 'learning_rate': 1.4819047619047618e-06, 'epoch': 4.28}\n",
      "{'loss': 1.8427, 'learning_rate': 1.4742857142857144e-06, 'epoch': 4.29}\n",
      "{'loss': 2.0777, 'learning_rate': 1.4666666666666669e-06, 'epoch': 4.29}\n",
      "{'loss': 2.4962, 'learning_rate': 1.459047619047619e-06, 'epoch': 4.29}\n",
      "{'loss': 1.8591, 'learning_rate': 1.4514285714285713e-06, 'epoch': 4.3}\n",
      "{'loss': 2.2112, 'learning_rate': 1.443809523809524e-06, 'epoch': 4.3}\n",
      "{'loss': 2.226, 'learning_rate': 1.4361904761904764e-06, 'epoch': 4.3}\n",
      "{'loss': 2.5083, 'learning_rate': 1.4285714285714286e-06, 'epoch': 4.31}\n",
      "{'loss': 2.0903, 'learning_rate': 1.4209523809523813e-06, 'epoch': 4.31}\n",
      "{'loss': 1.7797, 'learning_rate': 1.4133333333333335e-06, 'epoch': 4.32}\n",
      "{'loss': 2.3043, 'learning_rate': 1.4057142857142857e-06, 'epoch': 4.32}\n",
      "{'loss': 2.2477, 'learning_rate': 1.3980952380952382e-06, 'epoch': 4.32}\n",
      "{'loss': 2.1204, 'learning_rate': 1.3904761904761908e-06, 'epoch': 4.33}\n",
      "{'loss': 1.966, 'learning_rate': 1.382857142857143e-06, 'epoch': 4.33}\n",
      "{'loss': 2.0745, 'learning_rate': 1.3752380952380952e-06, 'epoch': 4.33}\n",
      "{'loss': 1.6523, 'learning_rate': 1.3676190476190477e-06, 'epoch': 4.34}\n",
      "{'loss': 2.1073, 'learning_rate': 1.3600000000000001e-06, 'epoch': 4.34}\n",
      "{'loss': 1.845, 'learning_rate': 1.3523809523809525e-06, 'epoch': 4.34}\n",
      "{'loss': 1.7164, 'learning_rate': 1.3447619047619048e-06, 'epoch': 4.35}\n",
      "{'loss': 1.9699, 'learning_rate': 1.3371428571428572e-06, 'epoch': 4.35}\n",
      "{'loss': 1.9639, 'learning_rate': 1.3295238095238096e-06, 'epoch': 4.36}\n",
      "{'loss': 2.4952, 'learning_rate': 1.321904761904762e-06, 'epoch': 4.36}\n",
      "{'loss': 2.1654, 'learning_rate': 1.3142857142857143e-06, 'epoch': 4.36}\n",
      "{'loss': 2.0232, 'learning_rate': 1.3066666666666667e-06, 'epoch': 4.37}\n",
      "{'loss': 1.9986, 'learning_rate': 1.2990476190476192e-06, 'epoch': 4.37}\n",
      "{'loss': 1.8817, 'learning_rate': 1.2914285714285716e-06, 'epoch': 4.37}\n",
      "{'loss': 1.8981, 'learning_rate': 1.2838095238095238e-06, 'epoch': 4.38}\n",
      "{'loss': 2.169, 'learning_rate': 1.2761904761904765e-06, 'epoch': 4.38}\n",
      "{'loss': 1.8181, 'learning_rate': 1.2685714285714287e-06, 'epoch': 4.38}\n",
      "{'loss': 2.1013, 'learning_rate': 1.2609523809523811e-06, 'epoch': 4.39}\n",
      "{'loss': 1.939, 'learning_rate': 1.2533333333333333e-06, 'epoch': 4.39}\n",
      "{'loss': 1.398, 'learning_rate': 1.2457142857142858e-06, 'epoch': 4.4}\n",
      "{'loss': 2.0175, 'learning_rate': 1.2380952380952382e-06, 'epoch': 4.4}\n",
      "{'loss': 2.3727, 'learning_rate': 1.2304761904761906e-06, 'epoch': 4.4}\n",
      "{'loss': 2.5961, 'learning_rate': 1.222857142857143e-06, 'epoch': 4.41}\n",
      "{'loss': 1.7556, 'learning_rate': 1.2152380952380953e-06, 'epoch': 4.41}\n",
      "{'loss': 1.9311, 'learning_rate': 1.2076190476190477e-06, 'epoch': 4.41}\n",
      "{'loss': 1.7085, 'learning_rate': 1.2000000000000002e-06, 'epoch': 4.42}\n",
      "{'loss': 2.0593, 'learning_rate': 1.1923809523809526e-06, 'epoch': 4.42}\n",
      "{'loss': 2.1097, 'learning_rate': 1.1847619047619048e-06, 'epoch': 4.43}\n",
      "{'loss': 1.9239, 'learning_rate': 1.1771428571428572e-06, 'epoch': 4.43}\n",
      "{'loss': 2.022, 'learning_rate': 1.1695238095238095e-06, 'epoch': 4.43}\n",
      "{'loss': 2.1263, 'learning_rate': 1.161904761904762e-06, 'epoch': 4.44}\n",
      "{'loss': 1.8863, 'learning_rate': 1.1542857142857143e-06, 'epoch': 4.44}\n",
      "{'loss': 2.1927, 'learning_rate': 1.1466666666666668e-06, 'epoch': 4.44}\n",
      "{'loss': 1.851, 'learning_rate': 1.1390476190476192e-06, 'epoch': 4.45}\n",
      "{'loss': 1.7446, 'learning_rate': 1.1314285714285714e-06, 'epoch': 4.45}\n",
      "{'loss': 1.345, 'learning_rate': 1.1238095238095239e-06, 'epoch': 4.45}\n",
      "{'loss': 2.3585, 'learning_rate': 1.1161904761904763e-06, 'epoch': 4.46}\n",
      "{'loss': 2.1374, 'learning_rate': 1.1085714285714287e-06, 'epoch': 4.46}\n",
      "{'loss': 2.2711, 'learning_rate': 1.100952380952381e-06, 'epoch': 4.47}\n",
      "{'loss': 1.6359, 'learning_rate': 1.0933333333333334e-06, 'epoch': 4.47}\n",
      "{'loss': 1.7614, 'learning_rate': 1.0857142857142858e-06, 'epoch': 4.47}\n",
      "{'loss': 2.148, 'learning_rate': 1.0780952380952383e-06, 'epoch': 4.48}\n",
      "{'loss': 2.2763, 'learning_rate': 1.0704761904761905e-06, 'epoch': 4.48}\n",
      "{'loss': 2.0189, 'learning_rate': 1.062857142857143e-06, 'epoch': 4.48}\n",
      "{'loss': 2.1062, 'learning_rate': 1.0552380952380953e-06, 'epoch': 4.49}\n",
      "{'loss': 2.1712, 'learning_rate': 1.0476190476190478e-06, 'epoch': 4.49}\n",
      "{'loss': 1.8937, 'learning_rate': 1.04e-06, 'epoch': 4.49}\n",
      "{'loss': 1.7579, 'learning_rate': 1.0323809523809524e-06, 'epoch': 4.5}\n",
      "{'loss': 1.8293, 'learning_rate': 1.0247619047619049e-06, 'epoch': 4.5}\n",
      "{'loss': 2.2904, 'learning_rate': 1.0171428571428573e-06, 'epoch': 4.51}\n",
      "{'loss': 2.5751, 'learning_rate': 1.0095238095238095e-06, 'epoch': 4.51}\n",
      "{'loss': 1.9022, 'learning_rate': 1.001904761904762e-06, 'epoch': 4.51}\n",
      "{'loss': 1.4314, 'learning_rate': 9.942857142857144e-07, 'epoch': 4.52}\n",
      "{'loss': 1.6552, 'learning_rate': 9.866666666666668e-07, 'epoch': 4.52}\n",
      "{'loss': 1.6272, 'learning_rate': 9.790476190476193e-07, 'epoch': 4.52}\n",
      "{'loss': 2.2221, 'learning_rate': 9.714285714285715e-07, 'epoch': 4.53}\n",
      "{'loss': 2.3665, 'learning_rate': 9.63809523809524e-07, 'epoch': 4.53}\n",
      "{'loss': 1.7663, 'learning_rate': 9.561904761904763e-07, 'epoch': 4.54}\n",
      "{'loss': 1.6771, 'learning_rate': 9.485714285714287e-07, 'epoch': 4.54}\n",
      "{'loss': 2.032, 'learning_rate': 9.40952380952381e-07, 'epoch': 4.54}\n",
      "{'loss': 1.8348, 'learning_rate': 9.333333333333334e-07, 'epoch': 4.55}\n",
      "{'loss': 2.0299, 'learning_rate': 9.257142857142858e-07, 'epoch': 4.55}\n",
      "{'loss': 1.8998, 'learning_rate': 9.180952380952382e-07, 'epoch': 4.55}\n",
      "{'loss': 2.1372, 'learning_rate': 9.104761904761905e-07, 'epoch': 4.56}\n",
      "{'loss': 1.9794, 'learning_rate': 9.02857142857143e-07, 'epoch': 4.56}\n",
      "{'loss': 2.1397, 'learning_rate': 8.952380952380953e-07, 'epoch': 4.56}\n",
      "{'loss': 2.2413, 'learning_rate': 8.876190476190477e-07, 'epoch': 4.57}\n",
      "{'loss': 2.1777, 'learning_rate': 8.8e-07, 'epoch': 4.57}\n",
      "{'loss': 2.2509, 'learning_rate': 8.723809523809525e-07, 'epoch': 4.58}\n",
      "{'loss': 2.0885, 'learning_rate': 8.647619047619048e-07, 'epoch': 4.58}\n",
      "{'loss': 1.7746, 'learning_rate': 8.571428571428572e-07, 'epoch': 4.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HOME\\anaconda3\\lib\\site-packages\\peft\\utils\\save_and_load.py:168: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7909, 'learning_rate': 8.495238095238096e-07, 'epoch': 4.59}\n",
      "{'loss': 2.0242, 'learning_rate': 8.41904761904762e-07, 'epoch': 4.59}\n",
      "{'loss': 1.7513, 'learning_rate': 8.342857142857144e-07, 'epoch': 4.59}\n",
      "{'loss': 1.8325, 'learning_rate': 8.266666666666668e-07, 'epoch': 4.6}\n",
      "{'loss': 1.7371, 'learning_rate': 8.190476190476192e-07, 'epoch': 4.6}\n",
      "{'loss': 1.7366, 'learning_rate': 8.114285714285715e-07, 'epoch': 4.6}\n",
      "{'loss': 1.8186, 'learning_rate': 8.03809523809524e-07, 'epoch': 4.61}\n",
      "{'loss': 2.2758, 'learning_rate': 7.961904761904763e-07, 'epoch': 4.61}\n",
      "{'loss': 1.9375, 'learning_rate': 7.885714285714287e-07, 'epoch': 4.62}\n",
      "{'loss': 1.7738, 'learning_rate': 7.809523809523809e-07, 'epoch': 4.62}\n",
      "{'loss': 2.1634, 'learning_rate': 7.733333333333335e-07, 'epoch': 4.62}\n",
      "{'loss': 1.8518, 'learning_rate': 7.657142857142857e-07, 'epoch': 4.63}\n",
      "{'loss': 2.3551, 'learning_rate': 7.580952380952381e-07, 'epoch': 4.63}\n",
      "{'loss': 1.881, 'learning_rate': 7.504761904761905e-07, 'epoch': 4.63}\n",
      "{'loss': 2.6313, 'learning_rate': 7.428571428571429e-07, 'epoch': 4.64}\n",
      "{'loss': 2.3263, 'learning_rate': 7.352380952380952e-07, 'epoch': 4.64}\n",
      "{'loss': 2.326, 'learning_rate': 7.276190476190477e-07, 'epoch': 4.65}\n",
      "{'loss': 1.9935, 'learning_rate': 7.2e-07, 'epoch': 4.65}\n",
      "{'loss': 1.8705, 'learning_rate': 7.123809523809524e-07, 'epoch': 4.65}\n",
      "{'loss': 1.7696, 'learning_rate': 7.047619047619048e-07, 'epoch': 4.66}\n",
      "{'loss': 1.6328, 'learning_rate': 6.971428571428572e-07, 'epoch': 4.66}\n",
      "{'loss': 1.5604, 'learning_rate': 6.895238095238095e-07, 'epoch': 4.66}\n",
      "{'loss': 1.7836, 'learning_rate': 6.819047619047619e-07, 'epoch': 4.67}\n",
      "{'loss': 2.4664, 'learning_rate': 6.742857142857144e-07, 'epoch': 4.67}\n",
      "{'loss': 1.9636, 'learning_rate': 6.666666666666667e-07, 'epoch': 4.67}\n",
      "{'loss': 1.905, 'learning_rate': 6.590476190476191e-07, 'epoch': 4.68}\n",
      "{'loss': 1.9165, 'learning_rate': 6.514285714285715e-07, 'epoch': 4.68}\n",
      "{'loss': 2.1455, 'learning_rate': 6.438095238095239e-07, 'epoch': 4.69}\n",
      "{'loss': 1.8246, 'learning_rate': 6.361904761904762e-07, 'epoch': 4.69}\n",
      "{'loss': 2.2119, 'learning_rate': 6.285714285714287e-07, 'epoch': 4.69}\n",
      "{'loss': 2.3919, 'learning_rate': 6.20952380952381e-07, 'epoch': 4.7}\n",
      "{'loss': 2.3491, 'learning_rate': 6.133333333333333e-07, 'epoch': 4.7}\n",
      "{'loss': 2.3834, 'learning_rate': 6.057142857142858e-07, 'epoch': 4.7}\n",
      "{'loss': 2.1424, 'learning_rate': 5.980952380952382e-07, 'epoch': 4.71}\n",
      "{'loss': 1.4353, 'learning_rate': 5.904761904761905e-07, 'epoch': 4.71}\n",
      "{'loss': 2.4911, 'learning_rate': 5.82857142857143e-07, 'epoch': 4.71}\n",
      "{'loss': 2.0707, 'learning_rate': 5.752380952380953e-07, 'epoch': 4.72}\n",
      "{'loss': 2.5516, 'learning_rate': 5.676190476190477e-07, 'epoch': 4.72}\n",
      "{'loss': 2.2406, 'learning_rate': 5.6e-07, 'epoch': 4.73}\n",
      "{'loss': 1.9295, 'learning_rate': 5.523809523809525e-07, 'epoch': 4.73}\n",
      "{'loss': 2.2584, 'learning_rate': 5.447619047619048e-07, 'epoch': 4.73}\n",
      "{'loss': 1.8631, 'learning_rate': 5.371428571428572e-07, 'epoch': 4.74}\n",
      "{'loss': 2.1704, 'learning_rate': 5.295238095238096e-07, 'epoch': 4.74}\n",
      "{'loss': 1.8551, 'learning_rate': 5.219047619047619e-07, 'epoch': 4.74}\n",
      "{'loss': 2.1233, 'learning_rate': 5.142857142857143e-07, 'epoch': 4.75}\n",
      "{'loss': 1.5465, 'learning_rate': 5.066666666666667e-07, 'epoch': 4.75}\n",
      "{'loss': 2.3437, 'learning_rate': 4.990476190476191e-07, 'epoch': 4.76}\n",
      "{'loss': 2.0716, 'learning_rate': 4.914285714285714e-07, 'epoch': 4.76}\n",
      "{'loss': 1.9586, 'learning_rate': 4.838095238095238e-07, 'epoch': 4.76}\n",
      "{'loss': 1.8414, 'learning_rate': 4.7619047619047623e-07, 'epoch': 4.77}\n",
      "{'loss': 1.8423, 'learning_rate': 4.6857142857142855e-07, 'epoch': 4.77}\n",
      "{'loss': 1.7315, 'learning_rate': 4.6095238095238094e-07, 'epoch': 4.77}\n",
      "{'loss': 1.7753, 'learning_rate': 4.533333333333334e-07, 'epoch': 4.78}\n",
      "{'loss': 1.9639, 'learning_rate': 4.457142857142858e-07, 'epoch': 4.78}\n",
      "{'loss': 2.2181, 'learning_rate': 4.3809523809523813e-07, 'epoch': 4.78}\n",
      "{'loss': 2.2207, 'learning_rate': 4.304761904761905e-07, 'epoch': 4.79}\n",
      "{'loss': 2.032, 'learning_rate': 4.228571428571429e-07, 'epoch': 4.79}\n",
      "{'loss': 1.6011, 'learning_rate': 4.1523809523809527e-07, 'epoch': 4.8}\n",
      "{'loss': 2.3576, 'learning_rate': 4.0761904761904765e-07, 'epoch': 4.8}\n",
      "{'loss': 2.2514, 'learning_rate': 4.0000000000000003e-07, 'epoch': 4.8}\n",
      "{'loss': 2.1669, 'learning_rate': 3.923809523809524e-07, 'epoch': 4.81}\n",
      "{'loss': 1.8012, 'learning_rate': 3.847619047619048e-07, 'epoch': 4.81}\n",
      "{'loss': 1.9507, 'learning_rate': 3.771428571428572e-07, 'epoch': 4.81}\n",
      "{'loss': 2.1268, 'learning_rate': 3.6952380952380956e-07, 'epoch': 4.82}\n",
      "{'loss': 1.7024, 'learning_rate': 3.6190476190476194e-07, 'epoch': 4.82}\n",
      "{'loss': 1.989, 'learning_rate': 3.542857142857143e-07, 'epoch': 4.82}\n",
      "{'loss': 1.6971, 'learning_rate': 3.466666666666667e-07, 'epoch': 4.83}\n",
      "{'loss': 2.026, 'learning_rate': 3.390476190476191e-07, 'epoch': 4.83}\n",
      "{'loss': 1.9837, 'learning_rate': 3.314285714285714e-07, 'epoch': 4.84}\n",
      "{'loss': 2.1497, 'learning_rate': 3.238095238095238e-07, 'epoch': 4.84}\n",
      "{'loss': 1.9429, 'learning_rate': 3.1619047619047617e-07, 'epoch': 4.84}\n",
      "{'loss': 1.9004, 'learning_rate': 3.085714285714286e-07, 'epoch': 4.85}\n",
      "{'loss': 1.6323, 'learning_rate': 3.00952380952381e-07, 'epoch': 4.85}\n",
      "{'loss': 2.052, 'learning_rate': 2.9333333333333337e-07, 'epoch': 4.85}\n",
      "{'loss': 1.9796, 'learning_rate': 2.8571428571428575e-07, 'epoch': 4.86}\n",
      "{'loss': 2.2145, 'learning_rate': 2.7809523809523813e-07, 'epoch': 4.86}\n",
      "{'loss': 1.83, 'learning_rate': 2.704761904761905e-07, 'epoch': 4.87}\n",
      "{'loss': 2.1565, 'learning_rate': 2.628571428571429e-07, 'epoch': 4.87}\n",
      "{'loss': 2.163, 'learning_rate': 2.5523809523809527e-07, 'epoch': 4.87}\n",
      "{'loss': 1.6814, 'learning_rate': 2.4761904761904765e-07, 'epoch': 4.88}\n",
      "{'loss': 2.2457, 'learning_rate': 2.4000000000000003e-07, 'epoch': 4.88}\n",
      "{'loss': 1.8728, 'learning_rate': 2.323809523809524e-07, 'epoch': 4.88}\n",
      "{'loss': 2.3181, 'learning_rate': 2.2476190476190477e-07, 'epoch': 4.89}\n",
      "{'loss': 2.1679, 'learning_rate': 2.1714285714285715e-07, 'epoch': 4.89}\n",
      "{'loss': 1.241, 'learning_rate': 2.0952380952380953e-07, 'epoch': 4.89}\n",
      "{'loss': 2.4601, 'learning_rate': 2.019047619047619e-07, 'epoch': 4.9}\n",
      "{'loss': 2.0918, 'learning_rate': 1.942857142857143e-07, 'epoch': 4.9}\n",
      "{'loss': 2.0556, 'learning_rate': 1.866666666666667e-07, 'epoch': 4.91}\n",
      "{'loss': 2.0118, 'learning_rate': 1.7904761904761908e-07, 'epoch': 4.91}\n",
      "{'loss': 2.4535, 'learning_rate': 1.7142857142857146e-07, 'epoch': 4.91}\n",
      "{'loss': 2.2185, 'learning_rate': 1.6380952380952384e-07, 'epoch': 4.92}\n",
      "{'loss': 2.4804, 'learning_rate': 1.561904761904762e-07, 'epoch': 4.92}\n",
      "{'loss': 1.819, 'learning_rate': 1.4857142857142857e-07, 'epoch': 4.92}\n",
      "{'loss': 1.9998, 'learning_rate': 1.4095238095238096e-07, 'epoch': 4.93}\n",
      "{'loss': 1.9937, 'learning_rate': 1.3333333333333336e-07, 'epoch': 4.93}\n",
      "{'loss': 2.1658, 'learning_rate': 1.2571428571428572e-07, 'epoch': 4.93}\n",
      "{'loss': 1.9405, 'learning_rate': 1.1809523809523811e-07, 'epoch': 4.94}\n",
      "{'loss': 2.3033, 'learning_rate': 1.1047619047619048e-07, 'epoch': 4.94}\n",
      "{'loss': 2.2154, 'learning_rate': 1.0285714285714286e-07, 'epoch': 4.95}\n",
      "{'loss': 1.4825, 'learning_rate': 9.523809523809525e-08, 'epoch': 4.95}\n",
      "{'loss': 1.8504, 'learning_rate': 8.761904761904763e-08, 'epoch': 4.95}\n",
      "{'loss': 1.8242, 'learning_rate': 8e-08, 'epoch': 4.96}\n",
      "{'loss': 1.8578, 'learning_rate': 7.238095238095238e-08, 'epoch': 4.96}\n",
      "{'loss': 2.1688, 'learning_rate': 6.476190476190478e-08, 'epoch': 4.96}\n",
      "{'loss': 2.7465, 'learning_rate': 5.714285714285715e-08, 'epoch': 4.97}\n",
      "{'loss': 2.2534, 'learning_rate': 4.9523809523809525e-08, 'epoch': 4.97}\n",
      "{'loss': 1.9773, 'learning_rate': 4.190476190476191e-08, 'epoch': 4.98}\n",
      "{'loss': 2.2261, 'learning_rate': 3.4285714285714286e-08, 'epoch': 4.98}\n",
      "{'loss': 2.1602, 'learning_rate': 2.6666666666666667e-08, 'epoch': 4.98}\n",
      "{'loss': 2.3651, 'learning_rate': 1.9047619047619048e-08, 'epoch': 4.99}\n",
      "{'loss': 2.0305, 'learning_rate': 1.142857142857143e-08, 'epoch': 4.99}\n",
      "{'loss': 1.959, 'learning_rate': 3.80952380952381e-09, 'epoch': 4.99}\n",
      "{'train_runtime': 970.385, 'train_samples_per_second': 11.238, 'train_steps_per_second': 2.808, 'train_loss': 17.079943937774097, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2725, training_loss=17.079943937774097, metrics={'train_runtime': 970.385, 'train_samples_per_second': 11.238, 'train_steps_per_second': 2.808, 'train_loss': 17.079943937774097, 'epoch': 5.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[50256, 47991,   250,   166,   113,   255,   168,   244,   112, 47991,\n",
      "           254,   168,    97,   226, 23821,   243,   234,   168,   243,   226,\n",
      "            30]])\n",
      "tensor([[50256, 47991,   250,   166,   113,   255,   168,   244,   112, 47991,\n",
      "           254,   168,    97,   226, 23821,   243,   234,   168,   243,   226,\n",
      "            30,   168,   226,   168,   243,   226,   168,   226,   168,   244,\n",
      "           112,   168,   244,   112,   168,   226,   168,   245,   168,   250,\n",
      "           222,   168,   244,   112,   168,   226,   226, 23821,   254,   168,\n",
      "           244,   168,   244,   112,   168,   226,   168,   244,   226,   168,\n",
      "           246,   168,   244,   168,   244,   112,   168,   226,   250, 23821,\n",
      "           244,   112,   168,   226, 47991,   246,   168,   244,   112, 23821,\n",
      "           244,   112,   168,   246,   168,   244,   112,   220,   166,   112,\n",
      "           112,   168,   226,   168,   245,   168,   226,   168,   248,   112,\n",
      "           168,   226,   168,   244,   112,   168,   226,   168,   244,   112,\n",
      "           220, 47991,   254, 23821,   244,   112,   168,   226,   168,   244,\n",
      "           112,   220,   166,   112,   168,   226,   220,   166,   250,   168,\n",
      "           244,   112, 23821,   226,   230,   112,   168,   244,   220,   166,\n",
      "           112,   168,   245,   112,   220,   166,   110,   168,   244,   112,\n",
      "           220,   166,   112,   220, 47991,   112,   220, 47991,   112,   220,\n",
      "         47991,   112,   112,   220, 47991,   112,   220, 47991,   250,   220,\n",
      "         47991,   112,   220, 47991,   250,   220,   112,   220,   169,   246,\n",
      "           168,   244,   112,   220, 47991,   112,   112,   168,   244,   220,\n",
      "           251,   168,   244,   112,   220,   242,   112,   220, 47991,   112,\n",
      "           112,   220, 47991,   112,   220,   166,   112, 23821,   246, 23821,\n",
      "           244,   220, 47991,   250,   220,   226,   112, 23821,   244,   112,\n",
      "           220, 47991,   112,   220, 47991,   112,   168,   244,   112,   220,\n",
      "           220,   230,   112,   112,   220,   112,   220,   112,   220, 47991,\n",
      "           250,   220,   230,   220,   112,   112,   220,   112,   220, 47991,\n",
      "           246, 23821,   246,   168,   250,   220,    97, 23821,   242,   112,\n",
      "           220, 47991,   112,   220,   112,   220,   112,   168,   244,   168,\n",
      "           246,   168,   244,   220, 47991,   112,   167,   112,   220, 47991,\n",
      "           112,   167,   244,   220,   112,   220,   250,   112,   112,   220,\n",
      "           112,   220,   112,   168,   244,   112,   220, 47991,   112,   220,\n",
      "           112,   112,   112,   220,   112,   112,   220, 47991,   112,   220,\n",
      "           246,   112,   220, 47991,   112,   220,   112,   220,   112,   220,\n",
      "           112,   220, 47991,   112,   112,   220,   112,   112,   112,   220,\n",
      "           112,   112,   220,    97,   220,   112,   220,   112,   112,   220,\n",
      "           112,   220,   230,   167,   112,   220,   112,   220,   112,   220,\n",
      "         47991,   112,   220,   112,   220,   112,   220,   246,   220,   246,\n",
      "           220,   242,   112,   220,   230,   112,   112,   112,   220,   112,\n",
      "           220,   112,   112,   220,   120, 47991,   112,   112,   112,   112,\n",
      "           112,   220,   112,   112,   112,   220,   112,   220, 47991,   112,\n",
      "           222,   112,   220, 47991,   112,   220,   244,   112,   244,   112,\n",
      "           112,   112,   112,   112,   112,   112,   112,   112,   112,   112,\n",
      "           220,   112,   246,   244,   112,   220,   112,   220,   112,   220,\n",
      "           246,   220,   112,   112,   112,   112,   112,   220, 47991,   112,\n",
      "           220,   112,   112,   220,   112,   220,   112,   220,   112,   220,\n",
      "           112,   220,   112,   220,   112,   220,   112,   112,   220,   112,\n",
      "           220,   112,   112,   112,   220,   112,   220,   112,   112,   112,\n",
      "           220,   112,   112,   220,   112,   220,   230,   112,   220,   112,\n",
      "           220,   112,   112,   112,   112,   220,   230,   112,   112,   220,\n",
      "           112,   112,   220, 47991,   112,   112,   220,   246,   220,   112,\n",
      "           112,   220,   112,   220,   112,   220,   112,   244,   112,   220]])\n",
      "DialoGPT: �아�어어��윀어섄 ��어�얄��어서 어�하어 어�어 괴���운�어�어 할 어�어 �� �어 섈�� �열 �어 � 해 해 해� 해 한 해 한 � �어 해�� �어 �� 해� 해 � � � 한 �� 어 해 해어  ��� � � 한 � �� � 하 �� � 씴 해 � ���� 해� 해� � ��� � �어 해 ��� �� 해 �� 해 � � � 해� ��� �� � � �� � �� � � 해 � � � � �� ���� � �� �해���� ��� � 해�� 해 �������������� ���� � � � ����� 해 �� � � � � � � �� � ��� � ��� �� � �� � ���� ��� �� 해� � �� � � ��� \n"
     ]
    }
   ],
   "source": [
    "infer_prompt = \"한국어할줄 알아?\"\n",
    "new_user_input_ids = tokenizer.encode(tokenizer.eos_token+infer_prompt,return_tensors='pt')\n",
    "print(new_user_input_ids)\n",
    "bot_input_ids = new_user_input_ids\n",
    "result_chat = trainer.model.generate(bot_input_ids,max_length = 500, pad_token_id = tokenizer.eos_token_id)\n",
    "print(result_chat)\n",
    "print(\"DialoGPT: {}\".format(tokenizer.decode(result_chat[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DialoGPT: 교통법규 위반곴�볘 였�늀곘 옼��곘늀곘 점곘디볘 � � 였� 옘�늀 겘옘렴늀� � �곘� � 였�늘�� 였�덀�던딘예�� �늘���늘늘�늘렀���늘 ���던던는� � �늘� � �늘 �늘늘�덍늘�늘덐��던��\n"
     ]
    }
   ],
   "source": [
    "infer_prompt = \"교통법규 위반\"\n",
    "new_user_input_ids = tokenizer.encode(tokenizer.eos_token+infer_prompt,return_tensors='pt')\n",
    "bot_input_ids = new_user_input_ids\n",
    "result_chat = model.generate(bot_input_ids,max_length = 256, pad_token_id = tokenizer.eos_token_id)\n",
    "print(\"DialoGPT: {}\".format(tokenizer.decode(result_chat[0], skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDialoGPT: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult_chat\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbot_input_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m))\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "print(\"DialoGPT: {}\".format(tokenizer.decode(result_chat[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
